{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1851468,"status":"ok","timestamp":1698084934464,"user":{"displayName":"SFVN Gamer","userId":"14323276225791406360"},"user_tz":-420},"id":"O8N4eVchz0XI","outputId":"ea4d2dae-e5ba-47f0-cb71-9cc4121fa72a"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-10-23 17:44:47.708202: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","True\n","Epoch \u001b[92m  1/20\u001b[00m:\n","- Step \u001b[96m   25/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.9423     - macro_f1    : 0.0006     - micro_f1    : 0.0100    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 3.9237     - val_macro_f1: 0.0015     - val_micro_f1: 0.0320    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m   50/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.9223     - macro_f1    : 0.0007     - micro_f1    : 0.0125    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 3.9025     - val_macro_f1: 0.0015     - val_micro_f1: 0.0320    \n","- Step \u001b[96m   75/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.9307     - macro_f1    : 0.0005     - micro_f1    : 0.0083    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 3.8653     - val_macro_f1: 0.0015     - val_micro_f1: 0.0320    \n","- Step \u001b[96m  100/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.9157     - macro_f1    : 0.0023     - micro_f1    : 0.0175    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 3.8167     - val_macro_f1: 0.0057     - val_micro_f1: 0.0660    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  125/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.8929     - macro_f1    : 0.0043     - micro_f1    : 0.0400    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 3.7554     - val_macro_f1: 0.0047     - val_micro_f1: 0.1080    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  150/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.8674     - macro_f1    : 0.0049     - micro_f1    : 0.0583    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 3.6839     - val_macro_f1: 0.0047     - val_micro_f1: 0.1100    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  175/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.8376     - macro_f1    : 0.0055     - micro_f1    : 0.0779    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 3.6081     - val_macro_f1: 0.0047     - val_micro_f1: 0.1100    \n","- Step \u001b[96m  200/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.8065     - macro_f1    : 0.0058     - micro_f1    : 0.0912    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 3.5538     - val_macro_f1: 0.0047     - val_micro_f1: 0.1100    \n","- Step \u001b[96m  225/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.7741     - macro_f1    : 0.0060     - micro_f1    : 0.1011    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 3.4847     - val_macro_f1: 0.0047     - val_micro_f1: 0.1100    \n","- Step \u001b[96m  250/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.7421     - macro_f1    : 0.0060     - micro_f1    : 0.1065    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 3.4155     - val_macro_f1: 0.0047     - val_micro_f1: 0.1100    \n","- Step \u001b[96m  275/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.7026     - macro_f1    : 0.0062     - micro_f1    : 0.1150    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 3.3465     - val_macro_f1: 0.0047     - val_micro_f1: 0.1100    \n","- Step \u001b[96m  300/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.6678     - macro_f1    : 0.0063     - micro_f1    : 0.1221    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 3.2641     - val_macro_f1: 0.0047     - val_micro_f1: 0.1100    \n","- Step \u001b[96m  325/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.6284     - macro_f1    : 0.0064     - micro_f1    : 0.1285    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 3.1852     - val_macro_f1: 0.0047     - val_micro_f1: 0.1100    \n","- Step \u001b[96m  350/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.6026     - macro_f1    : 0.0067     - micro_f1    : 0.1293    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 3.1148     - val_macro_f1: 0.0258     - val_micro_f1: 0.3100    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  375/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.5804     - macro_f1    : 0.0079     - micro_f1    : 0.1333    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 3.0394     - val_macro_f1: 0.0378     - val_micro_f1: 0.4120    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  400/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.5532     - macro_f1    : 0.0096     - micro_f1    : 0.1397    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 2.9721     - val_macro_f1: 0.0383     - val_micro_f1: 0.4180    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  425/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.5337     - macro_f1    : 0.0110     - micro_f1    : 0.1438    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 2.8950     - val_macro_f1: 0.0702     - val_micro_f1: 0.4180    \n","- Step \u001b[96m  450/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.5094     - macro_f1    : 0.0130     - micro_f1    : 0.1500    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 2.8141     - val_macro_f1: 0.0677     - val_micro_f1: 0.4080    \n","- Step \u001b[96m  475/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.4818     - macro_f1    : 0.0145     - micro_f1    : 0.1555    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 2.7535     - val_macro_f1: 0.0565     - val_micro_f1: 0.4060    \n","- Step \u001b[96m  500/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.4508     - macro_f1    : 0.0163     - micro_f1    : 0.1612    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 2.6995     - val_macro_f1: 0.0602     - val_micro_f1: 0.4180    \n","- Step \u001b[96m  525/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.4148     - macro_f1    : 0.0198     - micro_f1    : 0.1714    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 2.6177     - val_macro_f1: 0.0820     - val_micro_f1: 0.5120    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  550/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.3846     - macro_f1    : 0.0233     - micro_f1    : 0.1809    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 2.4940     - val_macro_f1: 0.0908     - val_micro_f1: 0.5480    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  575/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.3447     - macro_f1    : 0.0279     - micro_f1    : 0.1939    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 2.3992     - val_macro_f1: 0.0888     - val_micro_f1: 0.5420    \n","- Step \u001b[96m  600/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.3050     - macro_f1    : 0.0317     - micro_f1    : 0.2046    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 2.2867     - val_macro_f1: 0.0936     - val_micro_f1: 0.5600    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  625/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.2693     - macro_f1    : 0.0339     - micro_f1    : 0.2138    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 2.1922     - val_macro_f1: 0.0957     - val_micro_f1: 0.5680    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  650/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.2314     - macro_f1    : 0.0372     - micro_f1    : 0.2229    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 2.1219     - val_macro_f1: 0.0988     - val_micro_f1: 0.5700    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  675/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.1955     - macro_f1    : 0.0400     - micro_f1    : 0.2326    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 2.0723     - val_macro_f1: 0.1287     - val_micro_f1: 0.5820    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  682/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 3.1845     - macro_f1    : 0.0417     - micro_f1    : 0.2357    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 2.0468     - val_macro_f1: 0.1305     - val_micro_f1: 0.5840    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","Epoch \u001b[92m  2/20\u001b[00m:\n","- Step \u001b[96m   15/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.8336     - macro_f1    : 0.2750     - micro_f1    : 0.6500    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 2.0112     - val_macro_f1: 0.1405     - val_micro_f1: 0.5900    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m   40/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.9543     - macro_f1    : 0.1883     - micro_f1    : 0.5812    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.9398     - val_macro_f1: 0.1353     - val_micro_f1: 0.5860    \n","- Step \u001b[96m   65/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.9145     - macro_f1    : 0.1661     - micro_f1    : 0.5808    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.8805     - val_macro_f1: 0.1346     - val_micro_f1: 0.5920    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m   90/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.9309     - macro_f1    : 0.1682     - micro_f1    : 0.5653    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.8234     - val_macro_f1: 0.1406     - val_micro_f1: 0.6080    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  115/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.8828     - macro_f1    : 0.1670     - micro_f1    : 0.5859    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.7926     - val_macro_f1: 0.1775     - val_micro_f1: 0.6260    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  140/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.8600     - macro_f1    : 0.1627     - micro_f1    : 0.5902    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.7451     - val_macro_f1: 0.1731     - val_micro_f1: 0.6180    \n","- Step \u001b[96m  165/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.8147     - macro_f1    : 0.1675     - micro_f1    : 0.5947    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.6894     - val_macro_f1: 0.1912     - val_micro_f1: 0.6320    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  190/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.7765     - macro_f1    : 0.1726     - micro_f1    : 0.6020    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.5924     - val_macro_f1: 0.1841     - val_micro_f1: 0.6340    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  215/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.7324     - macro_f1    : 0.1727     - micro_f1    : 0.6122    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.5748     - val_macro_f1: 0.1945     - val_micro_f1: 0.6440    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  240/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.6979     - macro_f1    : 0.1792     - micro_f1    : 0.6203    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.6340     - val_macro_f1: 0.1869     - val_micro_f1: 0.6380    \n","- Step \u001b[96m  265/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.6772     - macro_f1    : 0.1828     - micro_f1    : 0.6241    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.6963     - val_macro_f1: 0.1819     - val_micro_f1: 0.6260    \n","- Step \u001b[96m  290/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.6578     - macro_f1    : 0.1868     - micro_f1    : 0.6276    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.4772     - val_macro_f1: 0.2131     - val_micro_f1: 0.6460    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  315/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.6344     - macro_f1    : 0.1952     - micro_f1    : 0.6321    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.4167     - val_macro_f1: 0.2491     - val_micro_f1: 0.6620    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  340/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.6099     - macro_f1    : 0.1994     - micro_f1    : 0.6393    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.5255     - val_macro_f1: 0.2440     - val_micro_f1: 0.6620    \n","- Step \u001b[96m  365/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.5890     - macro_f1    : 0.2042     - micro_f1    : 0.6428    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.4086     - val_macro_f1: 0.2517     - val_micro_f1: 0.6620    \n","- Step \u001b[96m  390/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.5733     - macro_f1    : 0.2110     - micro_f1    : 0.6449    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.3289     - val_macro_f1: 0.2657     - val_micro_f1: 0.6740    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  415/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.5578     - macro_f1    : 0.2221     - micro_f1    : 0.6491    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.3423     - val_macro_f1: 0.2889     - val_micro_f1: 0.6800    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  440/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.5357     - macro_f1    : 0.2303     - micro_f1    : 0.6526    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.2616     - val_macro_f1: 0.3340     - val_micro_f1: 0.7000    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  465/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.5197     - macro_f1    : 0.2376     - micro_f1    : 0.6551    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.2548     - val_macro_f1: 0.3178     - val_micro_f1: 0.6800    \n","- Step \u001b[96m  490/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.4968     - macro_f1    : 0.2430     - micro_f1    : 0.6592    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.1998     - val_macro_f1: 0.3054     - val_micro_f1: 0.6860    \n","- Step \u001b[96m  515/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.4882     - macro_f1    : 0.2482     - micro_f1    : 0.6604    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.1632     - val_macro_f1: 0.3687     - val_micro_f1: 0.7140    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  540/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.4672     - macro_f1    : 0.2554     - micro_f1    : 0.6655    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.2247     - val_macro_f1: 0.3214     - val_micro_f1: 0.6800    \n","- Step \u001b[96m  565/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.4584     - macro_f1    : 0.2597     - micro_f1    : 0.6668    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.1690     - val_macro_f1: 0.3393     - val_micro_f1: 0.7020    \n","- Step \u001b[96m  590/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.4467     - macro_f1    : 0.2633     - micro_f1    : 0.6680    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.1462     - val_macro_f1: 0.3749     - val_micro_f1: 0.7160    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  615/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.4279     - macro_f1    : 0.2684     - micro_f1    : 0.6720    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.1319     - val_macro_f1: 0.3640     - val_micro_f1: 0.7120    \n","- Step \u001b[96m  640/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.4061     - macro_f1    : 0.2762     - micro_f1    : 0.6771    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.1042     - val_macro_f1: 0.3786     - val_micro_f1: 0.7280    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  665/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.3914     - macro_f1    : 0.2790     - micro_f1    : 0.6806    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.0670     - val_macro_f1: 0.3933     - val_micro_f1: 0.7260    \n","- Step \u001b[96m  682/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 1.3833     - macro_f1    : 0.2788     - micro_f1    : 0.6805    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.1081     - val_macro_f1: 0.4069     - val_micro_f1: 0.7220    \n","Epoch \u001b[92m  3/20\u001b[00m:\n","- Step \u001b[96m    5/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.9360     - macro_f1    : 0.5783     - micro_f1    : 0.7750    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.1014     - val_macro_f1: 0.4126     - val_micro_f1: 0.7240    \n","- Step \u001b[96m   30/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.9401     - macro_f1    : 0.4621     - micro_f1    : 0.7333    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.0199     - val_macro_f1: 0.4386     - val_micro_f1: 0.7580    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m   55/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.9064     - macro_f1    : 0.4827     - micro_f1    : 0.7750    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.0910     - val_macro_f1: 0.4243     - val_micro_f1: 0.7360    \n","- Step \u001b[96m   80/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.8799     - macro_f1    : 0.4637     - micro_f1    : 0.7844    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.0438     - val_macro_f1: 0.4457     - val_micro_f1: 0.7420    \n","- Step \u001b[96m  105/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.8633     - macro_f1    : 0.4527     - micro_f1    : 0.7869    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.0235     - val_macro_f1: 0.4770     - val_micro_f1: 0.7520    \n","- Step \u001b[96m  130/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.8250     - macro_f1    : 0.4480     - micro_f1    : 0.7981    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.9975     - val_macro_f1: 0.4670     - val_micro_f1: 0.7440    \n","- Step \u001b[96m  155/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.8221     - macro_f1    : 0.4560     - micro_f1    : 0.8008    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.9865     - val_macro_f1: 0.5181     - val_micro_f1: 0.7620    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  180/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.8192     - macro_f1    : 0.4465     - micro_f1    : 0.8014    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.0334     - val_macro_f1: 0.5072     - val_micro_f1: 0.7480    \n","- Step \u001b[96m  205/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.8245     - macro_f1    : 0.4531     - micro_f1    : 0.8000    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.1187     - val_macro_f1: 0.5057     - val_micro_f1: 0.7260    \n","- Step \u001b[96m  230/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.8050     - macro_f1    : 0.4570     - micro_f1    : 0.8054    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.0552     - val_macro_f1: 0.5374     - val_micro_f1: 0.7540    \n","- Step \u001b[96m  255/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.7931     - macro_f1    : 0.4722     - micro_f1    : 0.8103    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.9973     - val_macro_f1: 0.5496     - val_micro_f1: 0.7740    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  280/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.7851     - macro_f1    : 0.4791     - micro_f1    : 0.8125    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.9191     - val_macro_f1: 0.5435     - val_micro_f1: 0.7920    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  305/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.7732     - macro_f1    : 0.4841     - micro_f1    : 0.8160    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8977     - val_macro_f1: 0.5536     - val_micro_f1: 0.7860    \n","- Step \u001b[96m  330/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.7588     - macro_f1    : 0.4902     - micro_f1    : 0.8189    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.9402     - val_macro_f1: 0.5213     - val_micro_f1: 0.7660    \n","- Step \u001b[96m  355/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.7489     - macro_f1    : 0.4916     - micro_f1    : 0.8211    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.9650     - val_macro_f1: 0.5431     - val_micro_f1: 0.7680    \n","- Step \u001b[96m  380/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.7400     - macro_f1    : 0.4964     - micro_f1    : 0.8224    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.9414     - val_macro_f1: 0.5382     - val_micro_f1: 0.7780    \n","- Step \u001b[96m  405/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.7435     - macro_f1    : 0.4991     - micro_f1    : 0.8213    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 1.0207     - val_macro_f1: 0.5398     - val_micro_f1: 0.7640    \n","- Step \u001b[96m  430/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.7369     - macro_f1    : 0.5037     - micro_f1    : 0.8218    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.9592     - val_macro_f1: 0.5532     - val_micro_f1: 0.7720    \n","- Step \u001b[96m  455/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.7444     - macro_f1    : 0.5061     - micro_f1    : 0.8198    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8840     - val_macro_f1: 0.6076     - val_micro_f1: 0.7860    \n","- Step \u001b[96m  480/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.7440     - macro_f1    : 0.5108     - micro_f1    : 0.8195    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8705     - val_macro_f1: 0.5826     - val_micro_f1: 0.7880    \n","- Step \u001b[96m  505/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.7432     - macro_f1    : 0.5121     - micro_f1    : 0.8200    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8293     - val_macro_f1: 0.5638     - val_micro_f1: 0.8000    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  530/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.7374     - macro_f1    : 0.5150     - micro_f1    : 0.8219    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.9242     - val_macro_f1: 0.5745     - val_micro_f1: 0.7960    \n","- Step \u001b[96m  555/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.7344     - macro_f1    : 0.5167     - micro_f1    : 0.8216    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8670     - val_macro_f1: 0.5405     - val_micro_f1: 0.7860    \n","- Step \u001b[96m  580/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.7379     - macro_f1    : 0.5199     - micro_f1    : 0.8211    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8696     - val_macro_f1: 0.5588     - val_micro_f1: 0.7820    \n","- Step \u001b[96m  605/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.7368     - macro_f1    : 0.5196     - micro_f1    : 0.8217    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7826     - val_macro_f1: 0.5607     - val_micro_f1: 0.8080    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  630/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.7309     - macro_f1    : 0.5273     - micro_f1    : 0.8236    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8861     - val_macro_f1: 0.5790     - val_micro_f1: 0.8060    \n","- Step \u001b[96m  655/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.7237     - macro_f1    : 0.5298     - micro_f1    : 0.8254    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7973     - val_macro_f1: 0.5676     - val_micro_f1: 0.8080    \n","- Step \u001b[96m  680/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.7245     - macro_f1    : 0.5344     - micro_f1    : 0.8244    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8117     - val_macro_f1: 0.5349     - val_micro_f1: 0.8000    \n","- Step \u001b[96m  682/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.7227     - macro_f1    : 0.5347     - micro_f1    : 0.8248    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8389     - val_macro_f1: 0.5395     - val_micro_f1: 0.8040    \n","Epoch \u001b[92m  4/20\u001b[00m:\n","- Step \u001b[96m   20/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.6739     - macro_f1    : 0.7025     - micro_f1    : 0.8312    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8664     - val_macro_f1: 0.5416     - val_micro_f1: 0.8040    \n","- Step \u001b[96m   45/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.6005     - macro_f1    : 0.6726     - micro_f1    : 0.8472    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7673     - val_macro_f1: 0.5783     - val_micro_f1: 0.8180    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m   70/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.5765     - macro_f1    : 0.6580     - micro_f1    : 0.8518    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8513     - val_macro_f1: 0.5915     - val_micro_f1: 0.8040    \n","- Step \u001b[96m   95/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.5996     - macro_f1    : 0.6240     - micro_f1    : 0.8421    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8446     - val_macro_f1: 0.6003     - val_micro_f1: 0.8000    \n","- Step \u001b[96m  120/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.5705     - macro_f1    : 0.6256     - micro_f1    : 0.8510    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7987     - val_macro_f1: 0.6321     - val_micro_f1: 0.8140    \n","- Step \u001b[96m  145/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.5216     - macro_f1    : 0.6176     - micro_f1    : 0.8629    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8133     - val_macro_f1: 0.6174     - val_micro_f1: 0.8040    \n","- Step \u001b[96m  170/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.4987     - macro_f1    : 0.6393     - micro_f1    : 0.8721    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8313     - val_macro_f1: 0.6147     - val_micro_f1: 0.8080    \n","- Step \u001b[96m  195/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.4850     - macro_f1    : 0.6427     - micro_f1    : 0.8744    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8389     - val_macro_f1: 0.6032     - val_micro_f1: 0.7980    \n","- Step \u001b[96m  220/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.4750     - macro_f1    : 0.6399     - micro_f1    : 0.8761    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8336     - val_macro_f1: 0.5959     - val_micro_f1: 0.7920    \n","- Step \u001b[96m  245/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.4766     - macro_f1    : 0.6244     - micro_f1    : 0.8740    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8935     - val_macro_f1: 0.5859     - val_micro_f1: 0.7640    \n","- Step \u001b[96m  270/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.4915     - macro_f1    : 0.6287     - micro_f1    : 0.8718    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8297     - val_macro_f1: 0.5768     - val_micro_f1: 0.7920    \n","- Step \u001b[96m  295/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.4819     - macro_f1    : 0.6288     - micro_f1    : 0.8737    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8305     - val_macro_f1: 0.5869     - val_micro_f1: 0.7940    \n","- Step \u001b[96m  320/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.4825     - macro_f1    : 0.6274     - micro_f1    : 0.8742    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8561     - val_macro_f1: 0.5723     - val_micro_f1: 0.7920    \n","- Step \u001b[96m  345/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.4735     - macro_f1    : 0.6291     - micro_f1    : 0.8764    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8357     - val_macro_f1: 0.5865     - val_micro_f1: 0.8000    \n","- Step \u001b[96m  370/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.4708     - macro_f1    : 0.6318     - micro_f1    : 0.8767    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8271     - val_macro_f1: 0.6076     - val_micro_f1: 0.8080    \n","- Step \u001b[96m  395/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.4701     - macro_f1    : 0.6240     - micro_f1    : 0.8782    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8257     - val_macro_f1: 0.5853     - val_micro_f1: 0.8020    \n","- Step \u001b[96m  420/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.4669     - macro_f1    : 0.6274     - micro_f1    : 0.8798    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8171     - val_macro_f1: 0.5922     - val_micro_f1: 0.8000    \n","- Step \u001b[96m  445/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.4661     - macro_f1    : 0.6306     - micro_f1    : 0.8798    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7800     - val_macro_f1: 0.6041     - val_micro_f1: 0.8080    \n","- Step \u001b[96m  470/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.4716     - macro_f1    : 0.6444     - micro_f1    : 0.8798    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7376     - val_macro_f1: 0.6420     - val_micro_f1: 0.8180    \n","- Step \u001b[96m  495/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.4646     - macro_f1    : 0.6477     - micro_f1    : 0.8826    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7334     - val_macro_f1: 0.6334     - val_micro_f1: 0.8100    \n","- Step \u001b[96m  520/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.4584     - macro_f1    : 0.6486     - micro_f1    : 0.8841    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7426     - val_macro_f1: 0.6464     - val_micro_f1: 0.8180    \n","- Step \u001b[96m  545/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.4539     - macro_f1    : 0.6508     - micro_f1    : 0.8849    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7590     - val_macro_f1: 0.6223     - val_micro_f1: 0.8120    \n","- Step \u001b[96m  570/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.4501     - macro_f1    : 0.6515     - micro_f1    : 0.8866    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7457     - val_macro_f1: 0.6068     - val_micro_f1: 0.8140    \n","- Step \u001b[96m  595/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.4463     - macro_f1    : 0.6566     - micro_f1    : 0.8876    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7623     - val_macro_f1: 0.6314     - val_micro_f1: 0.8100    \n","- Step \u001b[96m  620/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.4504     - macro_f1    : 0.6559     - micro_f1    : 0.8865    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7856     - val_macro_f1: 0.6230     - val_micro_f1: 0.8020    \n","- Step \u001b[96m  645/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.4471     - macro_f1    : 0.6562     - micro_f1    : 0.8878    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8476     - val_macro_f1: 0.6230     - val_micro_f1: 0.7800    \n","- Step \u001b[96m  670/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.4423     - macro_f1    : 0.6569     - micro_f1    : 0.8886    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7818     - val_macro_f1: 0.6121     - val_micro_f1: 0.8040    \n","- Step \u001b[96m  682/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.4436     - macro_f1    : 0.6570     - micro_f1    : 0.8883    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8317     - val_macro_f1: 0.6194     - val_micro_f1: 0.8020    \n","Epoch \u001b[92m  5/20\u001b[00m:\n","- Step \u001b[96m   10/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.4213     - macro_f1    : 0.7409     - micro_f1    : 0.9000    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8469     - val_macro_f1: 0.6302     - val_micro_f1: 0.8040    \n","- Step \u001b[96m   35/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.3708     - macro_f1    : 0.7964     - micro_f1    : 0.9036    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8003     - val_macro_f1: 0.6611     - val_micro_f1: 0.8240    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m   60/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.3335     - macro_f1    : 0.8001     - micro_f1    : 0.9146    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7788     - val_macro_f1: 0.6545     - val_micro_f1: 0.8320    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m   85/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.3175     - macro_f1    : 0.7565     - micro_f1    : 0.9162    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7999     - val_macro_f1: 0.6485     - val_micro_f1: 0.8240    \n","- Step \u001b[96m  110/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.3332     - macro_f1    : 0.7585     - micro_f1    : 0.9148    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8237     - val_macro_f1: 0.6257     - val_micro_f1: 0.8160    \n","- Step \u001b[96m  135/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.3323     - macro_f1    : 0.7427     - micro_f1    : 0.9130    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8372     - val_macro_f1: 0.6177     - val_micro_f1: 0.8220    \n","- Step \u001b[96m  160/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.3272     - macro_f1    : 0.7407     - micro_f1    : 0.9156    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8105     - val_macro_f1: 0.6421     - val_micro_f1: 0.8280    \n","- Step \u001b[96m  185/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.3058     - macro_f1    : 0.7453     - micro_f1    : 0.9216    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7622     - val_macro_f1: 0.6806     - val_micro_f1: 0.8280    \n","- Step \u001b[96m  210/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.2987     - macro_f1    : 0.7473     - micro_f1    : 0.9250    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8497     - val_macro_f1: 0.6552     - val_micro_f1: 0.8160    \n","- Step \u001b[96m  235/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.2914     - macro_f1    : 0.7441     - micro_f1    : 0.9250    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8818     - val_macro_f1: 0.6290     - val_micro_f1: 0.8040    \n","- Step \u001b[96m  260/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.2954     - macro_f1    : 0.7430     - micro_f1    : 0.9255    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.9053     - val_macro_f1: 0.6411     - val_micro_f1: 0.8100    \n","- Step \u001b[96m  285/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.2968     - macro_f1    : 0.7525     - micro_f1    : 0.9268    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8683     - val_macro_f1: 0.6639     - val_micro_f1: 0.8140    \n","- Step \u001b[96m  310/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.2917     - macro_f1    : 0.7502     - micro_f1    : 0.9274    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8482     - val_macro_f1: 0.6702     - val_micro_f1: 0.8180    \n","- Step \u001b[96m  335/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.2973     - macro_f1    : 0.7520     - micro_f1    : 0.9261    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8313     - val_macro_f1: 0.7008     - val_micro_f1: 0.8280    \n","- Step \u001b[96m  360/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.3129     - macro_f1    : 0.7496     - micro_f1    : 0.9219    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7960     - val_macro_f1: 0.7009     - val_micro_f1: 0.8260    \n","- Step \u001b[96m  385/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.3141     - macro_f1    : 0.7583     - micro_f1    : 0.9211    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7701     - val_macro_f1: 0.7122     - val_micro_f1: 0.8320    \n","- Step \u001b[96m  410/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.3149     - macro_f1    : 0.7611     - micro_f1    : 0.9198    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7479     - val_macro_f1: 0.6903     - val_micro_f1: 0.8420    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  435/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.3125     - macro_f1    : 0.7600     - micro_f1    : 0.9198    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7705     - val_macro_f1: 0.6881     - val_micro_f1: 0.8380    \n","- Step \u001b[96m  460/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.3096     - macro_f1    : 0.7637     - micro_f1    : 0.9201    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7798     - val_macro_f1: 0.6926     - val_micro_f1: 0.8360    \n","- Step \u001b[96m  485/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.3084     - macro_f1    : 0.7622     - micro_f1    : 0.9198    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7814     - val_macro_f1: 0.6809     - val_micro_f1: 0.8300    \n","- Step \u001b[96m  510/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.3027     - macro_f1    : 0.7662     - micro_f1    : 0.9218    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7818     - val_macro_f1: 0.6353     - val_micro_f1: 0.8220    \n","- Step \u001b[96m  535/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.2993     - macro_f1    : 0.7663     - micro_f1    : 0.9229    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7577     - val_macro_f1: 0.6537     - val_micro_f1: 0.8280    \n","- Step \u001b[96m  560/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.2977     - macro_f1    : 0.7683     - micro_f1    : 0.9243    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7280     - val_macro_f1: 0.6754     - val_micro_f1: 0.8400    \n","- Step \u001b[96m  585/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.2968     - macro_f1    : 0.7689     - micro_f1    : 0.9241    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7152     - val_macro_f1: 0.6709     - val_micro_f1: 0.8360    \n","- Step \u001b[96m  610/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.2985     - macro_f1    : 0.7684     - micro_f1    : 0.9238    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7103     - val_macro_f1: 0.6679     - val_micro_f1: 0.8300    \n","- Step \u001b[96m  635/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.2951     - macro_f1    : 0.7707     - micro_f1    : 0.9244    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7145     - val_macro_f1: 0.6587     - val_micro_f1: 0.8280    \n","- Step \u001b[96m  660/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.2963     - macro_f1    : 0.7697     - micro_f1    : 0.9239    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7118     - val_macro_f1: 0.6426     - val_micro_f1: 0.8180    \n","- Step \u001b[96m  682/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.2989     - macro_f1    : 0.7646     - micro_f1    : 0.9233    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6787     - val_macro_f1: 0.6409     - val_micro_f1: 0.8160    \n","Epoch \u001b[92m  6/20\u001b[00m:\n","- Step \u001b[96m   25/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1751     - macro_f1    : 0.9409     - micro_f1    : 0.9600    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6554     - val_macro_f1: 0.6593     - val_micro_f1: 0.8380    \n","- Step \u001b[96m   50/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1705     - macro_f1    : 0.9646     - micro_f1    : 0.9650    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6611     - val_macro_f1: 0.6503     - val_micro_f1: 0.8320    \n","- Step \u001b[96m   75/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1804     - macro_f1    : 0.9077     - micro_f1    : 0.9600    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6622     - val_macro_f1: 0.6853     - val_micro_f1: 0.8480    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  100/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1944     - macro_f1    : 0.9043     - micro_f1    : 0.9562    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6588     - val_macro_f1: 0.6823     - val_micro_f1: 0.8480    \n","- Step \u001b[96m  125/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.2130     - macro_f1    : 0.9008     - micro_f1    : 0.9510    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6441     - val_macro_f1: 0.7014     - val_micro_f1: 0.8500    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  150/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.2012     - macro_f1    : 0.8709     - micro_f1    : 0.9542    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6672     - val_macro_f1: 0.7194     - val_micro_f1: 0.8520    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  175/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1957     - macro_f1    : 0.8693     - micro_f1    : 0.9557    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7172     - val_macro_f1: 0.7203     - val_micro_f1: 0.8440    \n","- Step \u001b[96m  200/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1976     - macro_f1    : 0.8667     - micro_f1    : 0.9544    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7084     - val_macro_f1: 0.6838     - val_micro_f1: 0.8280    \n","- Step \u001b[96m  225/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1995     - macro_f1    : 0.8550     - micro_f1    : 0.9511    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6951     - val_macro_f1: 0.6915     - val_micro_f1: 0.8240    \n","- Step \u001b[96m  250/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1925     - macro_f1    : 0.8516     - micro_f1    : 0.9525    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6735     - val_macro_f1: 0.6958     - val_micro_f1: 0.8300    \n","- Step \u001b[96m  275/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1986     - macro_f1    : 0.8532     - micro_f1    : 0.9491    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6768     - val_macro_f1: 0.6627     - val_micro_f1: 0.8380    \n","- Step \u001b[96m  300/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1932     - macro_f1    : 0.8542     - micro_f1    : 0.9508    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7064     - val_macro_f1: 0.6721     - val_micro_f1: 0.8360    \n","- Step \u001b[96m  325/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1985     - macro_f1    : 0.8547     - micro_f1    : 0.9500    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7390     - val_macro_f1: 0.6949     - val_micro_f1: 0.8440    \n","- Step \u001b[96m  350/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1998     - macro_f1    : 0.8602     - micro_f1    : 0.9486    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7383     - val_macro_f1: 0.7044     - val_micro_f1: 0.8480    \n","- Step \u001b[96m  375/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1952     - macro_f1    : 0.8595     - micro_f1    : 0.9500    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6677     - val_macro_f1: 0.7176     - val_micro_f1: 0.8640    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  400/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1947     - macro_f1    : 0.8613     - micro_f1    : 0.9503    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6179     - val_macro_f1: 0.6898     - val_micro_f1: 0.8620    \n","- Step \u001b[96m  425/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1964     - macro_f1    : 0.8634     - micro_f1    : 0.9503    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6106     - val_macro_f1: 0.6913     - val_micro_f1: 0.8640    \n","- Step \u001b[96m  450/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1945     - macro_f1    : 0.8650     - micro_f1    : 0.9508    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6062     - val_macro_f1: 0.6972     - val_micro_f1: 0.8560    \n","- Step \u001b[96m  475/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1927     - macro_f1    : 0.8658     - micro_f1    : 0.9508    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6259     - val_macro_f1: 0.6977     - val_micro_f1: 0.8500    \n","- Step \u001b[96m  500/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1910     - macro_f1    : 0.8644     - micro_f1    : 0.9515    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6547     - val_macro_f1: 0.6950     - val_micro_f1: 0.8460    \n","- Step \u001b[96m  525/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1927     - macro_f1    : 0.8656     - micro_f1    : 0.9510    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6592     - val_macro_f1: 0.6951     - val_micro_f1: 0.8520    \n","- Step \u001b[96m  550/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1920     - macro_f1    : 0.8654     - micro_f1    : 0.9507    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6305     - val_macro_f1: 0.6979     - val_micro_f1: 0.8580    \n","- Step \u001b[96m  575/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1908     - macro_f1    : 0.8654     - micro_f1    : 0.9511    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6419     - val_macro_f1: 0.6963     - val_micro_f1: 0.8680    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  600/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1921     - macro_f1    : 0.8661     - micro_f1    : 0.9515    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6622     - val_macro_f1: 0.7220     - val_micro_f1: 0.8700    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  625/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1917     - macro_f1    : 0.8680     - micro_f1    : 0.9518    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6870     - val_macro_f1: 0.7187     - val_micro_f1: 0.8640    \n","- Step \u001b[96m  650/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1944     - macro_f1    : 0.8636     - micro_f1    : 0.9515    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6734     - val_macro_f1: 0.7407     - val_micro_f1: 0.8620    \n","- Step \u001b[96m  675/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1927     - macro_f1    : 0.8636     - micro_f1    : 0.9515    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6194     - val_macro_f1: 0.7310     - val_micro_f1: 0.8760    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  682/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1925     - macro_f1    : 0.8639     - micro_f1    : 0.9514    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6070     - val_macro_f1: 0.7328     - val_micro_f1: 0.8720    \n","Epoch \u001b[92m  7/20\u001b[00m:\n","- Step \u001b[96m   15/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1470     - macro_f1    : 0.9506     - micro_f1    : 0.9833    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6207     - val_macro_f1: 0.7070     - val_micro_f1: 0.8560    \n","- Step \u001b[96m   40/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1239     - macro_f1    : 0.9284     - micro_f1    : 0.9750    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6232     - val_macro_f1: 0.7364     - val_micro_f1: 0.8680    \n","- Step \u001b[96m   65/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1305     - macro_f1    : 0.9049     - micro_f1    : 0.9712    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6290     - val_macro_f1: 0.7185     - val_micro_f1: 0.8540    \n","- Step \u001b[96m   90/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1513     - macro_f1    : 0.8984     - micro_f1    : 0.9653    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6149     - val_macro_f1: 0.6901     - val_micro_f1: 0.8580    \n","- Step \u001b[96m  115/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1360     - macro_f1    : 0.9016     - micro_f1    : 0.9663    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6036     - val_macro_f1: 0.7032     - val_micro_f1: 0.8600    \n","- Step \u001b[96m  140/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1396     - macro_f1    : 0.8769     - micro_f1    : 0.9634    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6149     - val_macro_f1: 0.6883     - val_micro_f1: 0.8580    \n","- Step \u001b[96m  165/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1306     - macro_f1    : 0.8791     - micro_f1    : 0.9667    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6237     - val_macro_f1: 0.6876     - val_micro_f1: 0.8600    \n","- Step \u001b[96m  190/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1309     - macro_f1    : 0.8739     - micro_f1    : 0.9638    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.5975     - val_macro_f1: 0.7024     - val_micro_f1: 0.8540    \n","- Step \u001b[96m  215/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1232     - macro_f1    : 0.8831     - micro_f1    : 0.9674    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6086     - val_macro_f1: 0.6874     - val_micro_f1: 0.8580    \n","- Step \u001b[96m  240/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1250     - macro_f1    : 0.8824     - micro_f1    : 0.9672    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6366     - val_macro_f1: 0.7001     - val_micro_f1: 0.8580    \n","- Step \u001b[96m  265/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1215     - macro_f1    : 0.9050     - micro_f1    : 0.9684    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6430     - val_macro_f1: 0.7028     - val_micro_f1: 0.8600    \n","- Step \u001b[96m  290/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1229     - macro_f1    : 0.8989     - micro_f1    : 0.9685    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6277     - val_macro_f1: 0.7138     - val_micro_f1: 0.8600    \n","- Step \u001b[96m  315/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1244     - macro_f1    : 0.9045     - micro_f1    : 0.9683    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6065     - val_macro_f1: 0.7012     - val_micro_f1: 0.8640    \n","- Step \u001b[96m  340/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1273     - macro_f1    : 0.9017     - micro_f1    : 0.9673    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6128     - val_macro_f1: 0.6876     - val_micro_f1: 0.8680    \n","- Step \u001b[96m  365/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1258     - macro_f1    : 0.9047     - micro_f1    : 0.9678    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6480     - val_macro_f1: 0.7080     - val_micro_f1: 0.8620    \n","- Step \u001b[96m  390/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1272     - macro_f1    : 0.9010     - micro_f1    : 0.9676    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6499     - val_macro_f1: 0.7104     - val_micro_f1: 0.8620    \n","- Step \u001b[96m  415/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1310     - macro_f1    : 0.9005     - micro_f1    : 0.9663    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6661     - val_macro_f1: 0.7331     - val_micro_f1: 0.8640    \n","- Step \u001b[96m  440/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1344     - macro_f1    : 0.9079     - micro_f1    : 0.9656    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6853     - val_macro_f1: 0.7386     - val_micro_f1: 0.8700    \n","- Step \u001b[96m  465/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1320     - macro_f1    : 0.9111     - micro_f1    : 0.9659    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7285     - val_macro_f1: 0.7259     - val_micro_f1: 0.8560    \n","- Step \u001b[96m  490/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1311     - macro_f1    : 0.9099     - micro_f1    : 0.9658    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7506     - val_macro_f1: 0.7141     - val_micro_f1: 0.8460    \n","- Step \u001b[96m  515/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1304     - macro_f1    : 0.9122     - micro_f1    : 0.9660    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7317     - val_macro_f1: 0.7102     - val_micro_f1: 0.8480    \n","- Step \u001b[96m  540/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1318     - macro_f1    : 0.9109     - micro_f1    : 0.9657    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6833     - val_macro_f1: 0.6853     - val_micro_f1: 0.8500    \n","- Step \u001b[96m  565/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1320     - macro_f1    : 0.9112     - micro_f1    : 0.9659    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6724     - val_macro_f1: 0.6944     - val_micro_f1: 0.8480    \n","- Step \u001b[96m  590/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1309     - macro_f1    : 0.9121     - micro_f1    : 0.9659    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6652     - val_macro_f1: 0.7088     - val_micro_f1: 0.8540    \n","- Step \u001b[96m  615/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1316     - macro_f1    : 0.9126     - micro_f1    : 0.9657    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6824     - val_macro_f1: 0.7148     - val_micro_f1: 0.8520    \n","- Step \u001b[96m  640/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1309     - macro_f1    : 0.9088     - micro_f1    : 0.9656    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7124     - val_macro_f1: 0.7070     - val_micro_f1: 0.8500    \n","- Step \u001b[96m  665/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1327     - macro_f1    : 0.9079     - micro_f1    : 0.9658    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7279     - val_macro_f1: 0.7033     - val_micro_f1: 0.8500    \n","- Step \u001b[96m  682/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.1340     - macro_f1    : 0.9082     - micro_f1    : 0.9657    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7356     - val_macro_f1: 0.6897     - val_micro_f1: 0.8380    \n","Epoch \u001b[92m  8/20\u001b[00m:\n","- Step \u001b[96m    5/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0184     - macro_f1    : 1.0000     - micro_f1    : 1.0000    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7333     - val_macro_f1: 0.6900     - val_micro_f1: 0.8380    \n","- Step \u001b[96m   30/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0429     - macro_f1    : 0.9763     - micro_f1    : 0.9917    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7271     - val_macro_f1: 0.6897     - val_micro_f1: 0.8380    \n","- Step \u001b[96m   55/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0791     - macro_f1    : 0.9595     - micro_f1    : 0.9818    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7128     - val_macro_f1: 0.7101     - val_micro_f1: 0.8480    \n","- Step \u001b[96m   80/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0750     - macro_f1    : 0.9511     - micro_f1    : 0.9797    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6641     - val_macro_f1: 0.7069     - val_micro_f1: 0.8540    \n","- Step \u001b[96m  105/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0739     - macro_f1    : 0.9380     - micro_f1    : 0.9798    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6576     - val_macro_f1: 0.6963     - val_micro_f1: 0.8520    \n","- Step \u001b[96m  130/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0710     - macro_f1    : 0.9422     - micro_f1    : 0.9817    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6648     - val_macro_f1: 0.6928     - val_micro_f1: 0.8580    \n","- Step \u001b[96m  155/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0738     - macro_f1    : 0.9407     - micro_f1    : 0.9815    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6632     - val_macro_f1: 0.6979     - val_micro_f1: 0.8560    \n","- Step \u001b[96m  180/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0831     - macro_f1    : 0.9381     - micro_f1    : 0.9792    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7190     - val_macro_f1: 0.6928     - val_micro_f1: 0.8520    \n","- Step \u001b[96m  205/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0842     - macro_f1    : 0.9306     - micro_f1    : 0.9780    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7208     - val_macro_f1: 0.6925     - val_micro_f1: 0.8520    \n","- Step \u001b[96m  230/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0856     - macro_f1    : 0.9328     - micro_f1    : 0.9772    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6818     - val_macro_f1: 0.7043     - val_micro_f1: 0.8620    \n","- Step \u001b[96m  255/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0844     - macro_f1    : 0.9327     - micro_f1    : 0.9775    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6930     - val_macro_f1: 0.7135     - val_micro_f1: 0.8680    \n","- Step \u001b[96m  280/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0821     - macro_f1    : 0.9333     - micro_f1    : 0.9781    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7216     - val_macro_f1: 0.7244     - val_micro_f1: 0.8660    \n","- Step \u001b[96m  305/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0893     - macro_f1    : 0.9431     - micro_f1    : 0.9766    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7188     - val_macro_f1: 0.7413     - val_micro_f1: 0.8660    \n","- Step \u001b[96m  330/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0909     - macro_f1    : 0.9437     - micro_f1    : 0.9758    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6832     - val_macro_f1: 0.7421     - val_micro_f1: 0.8620    \n","- Step \u001b[96m  355/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0912     - macro_f1    : 0.9447     - micro_f1    : 0.9757    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7489     - val_macro_f1: 0.7353     - val_micro_f1: 0.8460    \n","- Step \u001b[96m  380/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0895     - macro_f1    : 0.9450     - micro_f1    : 0.9763    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7484     - val_macro_f1: 0.7140     - val_micro_f1: 0.8420    \n","- Step \u001b[96m  405/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0883     - macro_f1    : 0.9425     - micro_f1    : 0.9765    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6814     - val_macro_f1: 0.7408     - val_micro_f1: 0.8600    \n","- Step \u001b[96m  430/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0912     - macro_f1    : 0.9353     - micro_f1    : 0.9753    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7231     - val_macro_f1: 0.7361     - val_micro_f1: 0.8540    \n","- Step \u001b[96m  455/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0935     - macro_f1    : 0.9404     - micro_f1    : 0.9753    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6999     - val_macro_f1: 0.7424     - val_micro_f1: 0.8560    \n","- Step \u001b[96m  480/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0923     - macro_f1    : 0.9449     - micro_f1    : 0.9755    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7042     - val_macro_f1: 0.7297     - val_micro_f1: 0.8600    \n","- Step \u001b[96m  505/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0899     - macro_f1    : 0.9464     - micro_f1    : 0.9765    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6924     - val_macro_f1: 0.7463     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  530/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0898     - macro_f1    : 0.9445     - micro_f1    : 0.9764    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7132     - val_macro_f1: 0.7544     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  555/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0921     - macro_f1    : 0.9457     - micro_f1    : 0.9761    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7150     - val_macro_f1: 0.7522     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  580/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0905     - macro_f1    : 0.9448     - micro_f1    : 0.9763    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6808     - val_macro_f1: 0.7392     - val_micro_f1: 0.8700    \n","- Step \u001b[96m  605/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0895     - macro_f1    : 0.9405     - micro_f1    : 0.9764    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6902     - val_macro_f1: 0.7475     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  630/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0903     - macro_f1    : 0.9385     - micro_f1    : 0.9764    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6969     - val_macro_f1: 0.7488     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  655/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0904     - macro_f1    : 0.9403     - micro_f1    : 0.9763    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6638     - val_macro_f1: 0.7523     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  680/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0907     - macro_f1    : 0.9402     - micro_f1    : 0.9763    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6754     - val_macro_f1: 0.7390     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  682/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0919     - macro_f1    : 0.9399     - micro_f1    : 0.9762    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6802     - val_macro_f1: 0.7390     - val_micro_f1: 0.8720    \n","Epoch \u001b[92m  9/20\u001b[00m:\n","- Step \u001b[96m   20/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0414     - macro_f1    : 0.9851     - micro_f1    : 0.9938    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6742     - val_macro_f1: 0.7462     - val_micro_f1: 0.8780    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m   45/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0539     - macro_f1    : 0.9603     - micro_f1    : 0.9861    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6858     - val_macro_f1: 0.7401     - val_micro_f1: 0.8760    \n","- Step \u001b[96m   70/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0458     - macro_f1    : 0.9648     - micro_f1    : 0.9893    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6976     - val_macro_f1: 0.7408     - val_micro_f1: 0.8760    \n","- Step \u001b[96m   95/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0433     - macro_f1    : 0.9323     - micro_f1    : 0.9895    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6995     - val_macro_f1: 0.7360     - val_micro_f1: 0.8660    \n","- Step \u001b[96m  120/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0437     - macro_f1    : 0.9471     - micro_f1    : 0.9896    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7142     - val_macro_f1: 0.7337     - val_micro_f1: 0.8680    \n","- Step \u001b[96m  145/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0456     - macro_f1    : 0.9281     - micro_f1    : 0.9897    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7032     - val_macro_f1: 0.7472     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  170/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0487     - macro_f1    : 0.9270     - micro_f1    : 0.9890    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6964     - val_macro_f1: 0.7575     - val_micro_f1: 0.8820    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  195/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0527     - macro_f1    : 0.9225     - micro_f1    : 0.9878    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6674     - val_macro_f1: 0.7686     - val_micro_f1: 0.8820    \n","- Step \u001b[96m  220/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0560     - macro_f1    : 0.9315     - micro_f1    : 0.9858    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6878     - val_macro_f1: 0.7681     - val_micro_f1: 0.8800    \n","- Step \u001b[96m  245/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0620     - macro_f1    : 0.9313     - micro_f1    : 0.9847    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6693     - val_macro_f1: 0.7651     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  270/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0618     - macro_f1    : 0.9384     - micro_f1    : 0.9847    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6811     - val_macro_f1: 0.7657     - val_micro_f1: 0.8820    \n","- Step \u001b[96m  295/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0584     - macro_f1    : 0.9415     - micro_f1    : 0.9856    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7113     - val_macro_f1: 0.7372     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  320/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0581     - macro_f1    : 0.9388     - micro_f1    : 0.9852    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7090     - val_macro_f1: 0.7391     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  345/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0585     - macro_f1    : 0.9396     - micro_f1    : 0.9851    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6972     - val_macro_f1: 0.7153     - val_micro_f1: 0.8640    \n","- Step \u001b[96m  370/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0580     - macro_f1    : 0.9572     - micro_f1    : 0.9851    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7175     - val_macro_f1: 0.7146     - val_micro_f1: 0.8620    \n","- Step \u001b[96m  395/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0583     - macro_f1    : 0.9585     - micro_f1    : 0.9851    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7430     - val_macro_f1: 0.7051     - val_micro_f1: 0.8600    \n","- Step \u001b[96m  420/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0598     - macro_f1    : 0.9582     - micro_f1    : 0.9848    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7597     - val_macro_f1: 0.7015     - val_micro_f1: 0.8560    \n","- Step \u001b[96m  445/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0604     - macro_f1    : 0.9613     - micro_f1    : 0.9848    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7443     - val_macro_f1: 0.6944     - val_micro_f1: 0.8540    \n","- Step \u001b[96m  470/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0606     - macro_f1    : 0.9611     - micro_f1    : 0.9846    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7480     - val_macro_f1: 0.7181     - val_micro_f1: 0.8560    \n","- Step \u001b[96m  495/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0610     - macro_f1    : 0.9576     - micro_f1    : 0.9836    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7480     - val_macro_f1: 0.7041     - val_micro_f1: 0.8560    \n","- Step \u001b[96m  520/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0614     - macro_f1    : 0.9572     - micro_f1    : 0.9834    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7427     - val_macro_f1: 0.6966     - val_micro_f1: 0.8560    \n","- Step \u001b[96m  545/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0634     - macro_f1    : 0.9612     - micro_f1    : 0.9830    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7418     - val_macro_f1: 0.7300     - val_micro_f1: 0.8660    \n","- Step \u001b[96m  570/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0639     - macro_f1    : 0.9635     - micro_f1    : 0.9831    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7455     - val_macro_f1: 0.7346     - val_micro_f1: 0.8700    \n","- Step \u001b[96m  595/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0632     - macro_f1    : 0.9647     - micro_f1    : 0.9836    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7396     - val_macro_f1: 0.7196     - val_micro_f1: 0.8640    \n","- Step \u001b[96m  620/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0637     - macro_f1    : 0.9651     - micro_f1    : 0.9837    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7078     - val_macro_f1: 0.7257     - val_micro_f1: 0.8680    \n","- Step \u001b[96m  645/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0638     - macro_f1    : 0.9656     - micro_f1    : 0.9835    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7055     - val_macro_f1: 0.7399     - val_micro_f1: 0.8700    \n","- Step \u001b[96m  670/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0635     - macro_f1    : 0.9645     - micro_f1    : 0.9836    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6915     - val_macro_f1: 0.7449     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  682/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0629     - macro_f1    : 0.9648     - micro_f1    : 0.9837    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6978     - val_macro_f1: 0.7394     - val_micro_f1: 0.8720    \n","Epoch \u001b[92m 10/20\u001b[00m:\n","- Step \u001b[96m   10/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0601     - macro_f1    : 0.9426     - micro_f1    : 0.9750    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6849     - val_macro_f1: 0.7444     - val_micro_f1: 0.8760    \n","- Step \u001b[96m   35/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0366     - macro_f1    : 0.9416     - micro_f1    : 0.9821    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7032     - val_macro_f1: 0.7368     - val_micro_f1: 0.8660    \n","- Step \u001b[96m   60/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0237     - macro_f1    : 0.9772     - micro_f1    : 0.9896    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7308     - val_macro_f1: 0.7304     - val_micro_f1: 0.8640    \n","- Step \u001b[96m   85/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0331     - macro_f1    : 0.9773     - micro_f1    : 0.9868    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7261     - val_macro_f1: 0.7204     - val_micro_f1: 0.8620    \n","- Step \u001b[96m  110/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0347     - macro_f1    : 0.9810     - micro_f1    : 0.9875    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7678     - val_macro_f1: 0.7395     - val_micro_f1: 0.8700    \n","- Step \u001b[96m  135/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0365     - macro_f1    : 0.9791     - micro_f1    : 0.9870    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7604     - val_macro_f1: 0.7112     - val_micro_f1: 0.8700    \n","- Step \u001b[96m  160/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0371     - macro_f1    : 0.9722     - micro_f1    : 0.9867    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7723     - val_macro_f1: 0.7095     - val_micro_f1: 0.8700    \n","- Step \u001b[96m  185/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0411     - macro_f1    : 0.9624     - micro_f1    : 0.9858    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7484     - val_macro_f1: 0.7197     - val_micro_f1: 0.8800    \n","- Step \u001b[96m  210/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0486     - macro_f1    : 0.9452     - micro_f1    : 0.9845    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7007     - val_macro_f1: 0.7389     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  235/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0556     - macro_f1    : 0.9418     - micro_f1    : 0.9830    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6813     - val_macro_f1: 0.7692     - val_micro_f1: 0.8840    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  260/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0542     - macro_f1    : 0.9235     - micro_f1    : 0.9832    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6620     - val_macro_f1: 0.7509     - val_micro_f1: 0.8840    \n","- Step \u001b[96m  285/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0508     - macro_f1    : 0.9524     - micro_f1    : 0.9842    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6834     - val_macro_f1: 0.7592     - val_micro_f1: 0.8860    \n","There is already a model saved with the name qc/V2023-10-23, which will be overwritten by new version!\n","- Step \u001b[96m  310/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0524     - macro_f1    : 0.9556     - micro_f1    : 0.9835    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6928     - val_macro_f1: 0.7307     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  335/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0501     - macro_f1    : 0.9582     - micro_f1    : 0.9840    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6970     - val_macro_f1: 0.7271     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  360/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0499     - macro_f1    : 0.9556     - micro_f1    : 0.9840    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.6999     - val_macro_f1: 0.7318     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  385/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0506     - macro_f1    : 0.9585     - micro_f1    : 0.9841    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7164     - val_macro_f1: 0.7544     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  410/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0499     - macro_f1    : 0.9616     - micro_f1    : 0.9841    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7290     - val_macro_f1: 0.7449     - val_micro_f1: 0.8700    \n","- Step \u001b[96m  435/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0541     - macro_f1    : 0.9582     - micro_f1    : 0.9836    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7328     - val_macro_f1: 0.7312     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  460/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0551     - macro_f1    : 0.9597     - micro_f1    : 0.9834    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7073     - val_macro_f1: 0.7290     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  485/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0537     - macro_f1    : 0.9623     - micro_f1    : 0.9838    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7299     - val_macro_f1: 0.7256     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  510/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0535     - macro_f1    : 0.9637     - micro_f1    : 0.9841    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7409     - val_macro_f1: 0.7288     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  535/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0553     - macro_f1    : 0.9646     - micro_f1    : 0.9841    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7472     - val_macro_f1: 0.7266     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  560/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0539     - macro_f1    : 0.9659     - micro_f1    : 0.9846    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7507     - val_macro_f1: 0.7438     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  585/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0523     - macro_f1    : 0.9672     - micro_f1    : 0.9850    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7238     - val_macro_f1: 0.7486     - val_micro_f1: 0.8700    \n","- Step \u001b[96m  610/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0528     - macro_f1    : 0.9665     - micro_f1    : 0.9848    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7267     - val_macro_f1: 0.7538     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  635/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0521     - macro_f1    : 0.9674     - micro_f1    : 0.9850    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7672     - val_macro_f1: 0.7656     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  660/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0514     - macro_f1    : 0.9680     - micro_f1    : 0.9852    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7414     - val_macro_f1: 0.7530     - val_micro_f1: 0.8680    \n","- Step \u001b[96m  682/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0507     - macro_f1    : 0.9689     - micro_f1    : 0.9855    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7221     - val_macro_f1: 0.7395     - val_micro_f1: 0.8720    \n","Epoch \u001b[92m 11/20\u001b[00m:\n","- Step \u001b[96m   25/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0531     - macro_f1    : 0.9752     - micro_f1    : 0.9800    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7161     - val_macro_f1: 0.7440     - val_micro_f1: 0.8740    \n","- Step \u001b[96m   50/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0547     - macro_f1    : 0.9839     - micro_f1    : 0.9825    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7125     - val_macro_f1: 0.7532     - val_micro_f1: 0.8740    \n","- Step \u001b[96m   75/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0487     - macro_f1    : 0.9594     - micro_f1    : 0.9833    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7346     - val_macro_f1: 0.7540     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  100/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0400     - macro_f1    : 0.9648     - micro_f1    : 0.9862    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7611     - val_macro_f1: 0.7763     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  125/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0345     - macro_f1    : 0.9671     - micro_f1    : 0.9880    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7413     - val_macro_f1: 0.7875     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  150/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0345     - macro_f1    : 0.9770     - micro_f1    : 0.9875    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7356     - val_macro_f1: 0.7973     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  175/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0363     - macro_f1    : 0.9599     - micro_f1    : 0.9871    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7329     - val_macro_f1: 0.7730     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  200/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0327     - macro_f1    : 0.9764     - micro_f1    : 0.9888    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7331     - val_macro_f1: 0.7772     - val_micro_f1: 0.8800    \n","- Step \u001b[96m  225/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0313     - macro_f1    : 0.9772     - micro_f1    : 0.9894    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7348     - val_macro_f1: 0.7533     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  250/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0332     - macro_f1    : 0.9775     - micro_f1    : 0.9900    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7416     - val_macro_f1: 0.7627     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  275/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0350     - macro_f1    : 0.9771     - micro_f1    : 0.9895    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7407     - val_macro_f1: 0.7334     - val_micro_f1: 0.8680    \n","- Step \u001b[96m  300/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0329     - macro_f1    : 0.9777     - micro_f1    : 0.9904    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7711     - val_macro_f1: 0.7439     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  325/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0377     - macro_f1    : 0.9802     - micro_f1    : 0.9900    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7587     - val_macro_f1: 0.7628     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  350/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0371     - macro_f1    : 0.9785     - micro_f1    : 0.9896    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7520     - val_macro_f1: 0.7803     - val_micro_f1: 0.8700    \n","- Step \u001b[96m  375/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0384     - macro_f1    : 0.9808     - micro_f1    : 0.9897    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7764     - val_macro_f1: 0.7263     - val_micro_f1: 0.8680    \n","- Step \u001b[96m  400/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0393     - macro_f1    : 0.9816     - micro_f1    : 0.9897    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7855     - val_macro_f1: 0.7335     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  425/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0383     - macro_f1    : 0.9815     - micro_f1    : 0.9897    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7914     - val_macro_f1: 0.7286     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  450/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0378     - macro_f1    : 0.9825     - micro_f1    : 0.9900    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7948     - val_macro_f1: 0.7265     - val_micro_f1: 0.8660    \n","- Step \u001b[96m  475/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0371     - macro_f1    : 0.9841     - micro_f1    : 0.9903    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8006     - val_macro_f1: 0.7536     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  500/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0356     - macro_f1    : 0.9844     - micro_f1    : 0.9908    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8042     - val_macro_f1: 0.7526     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  525/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0351     - macro_f1    : 0.9835     - micro_f1    : 0.9910    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8147     - val_macro_f1: 0.7820     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  550/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0344     - macro_f1    : 0.9840     - micro_f1    : 0.9911    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7946     - val_macro_f1: 0.8076     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  575/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0361     - macro_f1    : 0.9839     - micro_f1    : 0.9909    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8129     - val_macro_f1: 0.7991     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  600/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0353     - macro_f1    : 0.9843     - micro_f1    : 0.9910    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8015     - val_macro_f1: 0.7886     - val_micro_f1: 0.8700    \n","- Step \u001b[96m  625/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0349     - macro_f1    : 0.9845     - micro_f1    : 0.9910    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7832     - val_macro_f1: 0.7765     - val_micro_f1: 0.8680    \n","- Step \u001b[96m  650/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0354     - macro_f1    : 0.9847     - micro_f1    : 0.9908    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7896     - val_macro_f1: 0.7598     - val_micro_f1: 0.8660    \n","- Step \u001b[96m  675/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0364     - macro_f1    : 0.9848     - micro_f1    : 0.9906    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8019     - val_macro_f1: 0.7398     - val_micro_f1: 0.8520    \n","- Step \u001b[96m  682/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0369     - macro_f1    : 0.9849     - micro_f1    : 0.9903    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8185     - val_macro_f1: 0.7476     - val_micro_f1: 0.8580    \n","Epoch \u001b[92m 12/20\u001b[00m:\n","- Step \u001b[96m   15/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0330     - macro_f1    : 0.9553     - micro_f1    : 0.9833    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8201     - val_macro_f1: 0.7376     - val_micro_f1: 0.8620    \n","- Step \u001b[96m   40/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0301     - macro_f1    : 0.9816     - micro_f1    : 0.9906    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8359     - val_macro_f1: 0.7247     - val_micro_f1: 0.8500    \n","- Step \u001b[96m   65/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0233     - macro_f1    : 0.9852     - micro_f1    : 0.9942    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8422     - val_macro_f1: 0.7521     - val_micro_f1: 0.8560    \n","- Step \u001b[96m   90/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0396     - macro_f1    : 0.9876     - micro_f1    : 0.9903    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8339     - val_macro_f1: 0.7469     - val_micro_f1: 0.8600    \n","- Step \u001b[96m  115/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0339     - macro_f1    : 0.9888     - micro_f1    : 0.9913    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8251     - val_macro_f1: 0.7311     - val_micro_f1: 0.8580    \n","- Step \u001b[96m  140/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0285     - macro_f1    : 0.9897     - micro_f1    : 0.9929    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8291     - val_macro_f1: 0.7456     - val_micro_f1: 0.8580    \n","- Step \u001b[96m  165/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0248     - macro_f1    : 0.9914     - micro_f1    : 0.9939    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8209     - val_macro_f1: 0.7575     - val_micro_f1: 0.8580    \n","- Step \u001b[96m  190/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0231     - macro_f1    : 0.9870     - micro_f1    : 0.9941    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7977     - val_macro_f1: 0.7464     - val_micro_f1: 0.8620    \n","- Step \u001b[96m  215/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0214     - macro_f1    : 0.9894     - micro_f1    : 0.9948    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7937     - val_macro_f1: 0.7388     - val_micro_f1: 0.8580    \n","- Step \u001b[96m  240/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0232     - macro_f1    : 0.9849     - micro_f1    : 0.9938    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7940     - val_macro_f1: 0.7325     - val_micro_f1: 0.8600    \n","- Step \u001b[96m  265/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0266     - macro_f1    : 0.9858     - micro_f1    : 0.9929    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7874     - val_macro_f1: 0.7352     - val_micro_f1: 0.8620    \n","- Step \u001b[96m  290/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0264     - macro_f1    : 0.9869     - micro_f1    : 0.9931    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7883     - val_macro_f1: 0.7289     - val_micro_f1: 0.8620    \n","- Step \u001b[96m  315/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0245     - macro_f1    : 0.9879     - micro_f1    : 0.9937    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7887     - val_macro_f1: 0.7417     - val_micro_f1: 0.8680    \n","- Step \u001b[96m  340/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0246     - macro_f1    : 0.9857     - micro_f1    : 0.9934    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8151     - val_macro_f1: 0.7564     - val_micro_f1: 0.8660    \n","- Step \u001b[96m  365/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0245     - macro_f1    : 0.9872     - micro_f1    : 0.9935    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8124     - val_macro_f1: 0.7464     - val_micro_f1: 0.8620    \n","- Step \u001b[96m  390/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0239     - macro_f1    : 0.9875     - micro_f1    : 0.9936    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8040     - val_macro_f1: 0.7374     - val_micro_f1: 0.8620    \n","- Step \u001b[96m  415/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0231     - macro_f1    : 0.9889     - micro_f1    : 0.9940    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8006     - val_macro_f1: 0.7310     - val_micro_f1: 0.8580    \n","- Step \u001b[96m  440/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0230     - macro_f1    : 0.9889     - micro_f1    : 0.9938    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7941     - val_macro_f1: 0.7492     - val_micro_f1: 0.8580    \n","- Step \u001b[96m  465/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0223     - macro_f1    : 0.9895     - micro_f1    : 0.9941    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7979     - val_macro_f1: 0.7427     - val_micro_f1: 0.8580    \n","- Step \u001b[96m  490/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0214     - macro_f1    : 0.9900     - micro_f1    : 0.9944    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7969     - val_macro_f1: 0.7421     - val_micro_f1: 0.8580    \n","- Step \u001b[96m  515/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0206     - macro_f1    : 0.9905     - micro_f1    : 0.9947    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7991     - val_macro_f1: 0.7594     - val_micro_f1: 0.8580    \n","- Step \u001b[96m  540/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0217     - macro_f1    : 0.9887     - micro_f1    : 0.9944    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7736     - val_macro_f1: 0.7717     - val_micro_f1: 0.8680    \n","- Step \u001b[96m  565/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0210     - macro_f1    : 0.9891     - micro_f1    : 0.9947    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7720     - val_macro_f1: 0.7801     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  590/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0204     - macro_f1    : 0.9896     - micro_f1    : 0.9949    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7548     - val_macro_f1: 0.7785     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  615/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0199     - macro_f1    : 0.9901     - micro_f1    : 0.9949    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7615     - val_macro_f1: 0.7647     - val_micro_f1: 0.8680    \n","- Step \u001b[96m  640/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0211     - macro_f1    : 0.9902     - micro_f1    : 0.9945    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7712     - val_macro_f1: 0.7612     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  665/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0233     - macro_f1    : 0.9897     - micro_f1    : 0.9942    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7860     - val_macro_f1: 0.7526     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  682/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0228     - macro_f1    : 0.9899     - micro_f1    : 0.9943    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7944     - val_macro_f1: 0.7586     - val_micro_f1: 0.8720    \n","Epoch \u001b[92m 13/20\u001b[00m:\n","- Step \u001b[96m    5/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0027     - macro_f1    : 1.0000     - micro_f1    : 1.0000    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7966     - val_macro_f1: 0.7586     - val_micro_f1: 0.8720    \n","- Step \u001b[96m   30/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0189     - macro_f1    : 0.9724     - micro_f1    : 0.9958    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8293     - val_macro_f1: 0.7714     - val_micro_f1: 0.8740    \n","- Step \u001b[96m   55/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0280     - macro_f1    : 0.9886     - micro_f1    : 0.9932    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8008     - val_macro_f1: 0.7522     - val_micro_f1: 0.8680    \n","- Step \u001b[96m   80/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0204     - macro_f1    : 0.9930     - micro_f1    : 0.9953    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7923     - val_macro_f1: 0.7485     - val_micro_f1: 0.8660    \n","- Step \u001b[96m  105/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0182     - macro_f1    : 0.9906     - micro_f1    : 0.9940    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8004     - val_macro_f1: 0.7434     - val_micro_f1: 0.8600    \n","- Step \u001b[96m  130/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0189     - macro_f1    : 0.9889     - micro_f1    : 0.9942    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7944     - val_macro_f1: 0.7487     - val_micro_f1: 0.8560    \n","- Step \u001b[96m  155/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0179     - macro_f1    : 0.9898     - micro_f1    : 0.9944    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7934     - val_macro_f1: 0.7376     - val_micro_f1: 0.8600    \n","- Step \u001b[96m  180/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0161     - macro_f1    : 0.9912     - micro_f1    : 0.9951    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8177     - val_macro_f1: 0.7588     - val_micro_f1: 0.8620    \n","- Step \u001b[96m  205/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0172     - macro_f1    : 0.9918     - micro_f1    : 0.9951    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8262     - val_macro_f1: 0.7738     - val_micro_f1: 0.8680    \n","- Step \u001b[96m  230/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0207     - macro_f1    : 0.9913     - micro_f1    : 0.9940    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8268     - val_macro_f1: 0.7733     - val_micro_f1: 0.8640    \n","- Step \u001b[96m  255/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0191     - macro_f1    : 0.9921     - micro_f1    : 0.9946    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8535     - val_macro_f1: 0.7846     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  280/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0182     - macro_f1    : 0.9921     - micro_f1    : 0.9946    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8581     - val_macro_f1: 0.7570     - val_micro_f1: 0.8700    \n","- Step \u001b[96m  305/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0185     - macro_f1    : 0.9925     - micro_f1    : 0.9947    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8268     - val_macro_f1: 0.7528     - val_micro_f1: 0.8700    \n","- Step \u001b[96m  330/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0175     - macro_f1    : 0.9928     - micro_f1    : 0.9947    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8079     - val_macro_f1: 0.7558     - val_micro_f1: 0.8700    \n","- Step \u001b[96m  355/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0169     - macro_f1    : 0.9936     - micro_f1    : 0.9951    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8095     - val_macro_f1: 0.7570     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  380/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0173     - macro_f1    : 0.9904     - micro_f1    : 0.9947    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7744     - val_macro_f1: 0.7525     - val_micro_f1: 0.8700    \n","- Step \u001b[96m  405/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0165     - macro_f1    : 0.9908     - micro_f1    : 0.9951    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7732     - val_macro_f1: 0.7482     - val_micro_f1: 0.8660    \n","- Step \u001b[96m  430/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0156     - macro_f1    : 0.9910     - micro_f1    : 0.9953    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7722     - val_macro_f1: 0.7570     - val_micro_f1: 0.8700    \n","- Step \u001b[96m  455/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0150     - macro_f1    : 0.9913     - micro_f1    : 0.9956    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8109     - val_macro_f1: 0.7520     - val_micro_f1: 0.8660    \n","- Step \u001b[96m  480/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0143     - macro_f1    : 0.9922     - micro_f1    : 0.9958    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7968     - val_macro_f1: 0.7548     - val_micro_f1: 0.8680    \n","- Step \u001b[96m  505/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0138     - macro_f1    : 0.9924     - micro_f1    : 0.9960    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7917     - val_macro_f1: 0.7592     - val_micro_f1: 0.8680    \n","- Step \u001b[96m  530/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0138     - macro_f1    : 0.9925     - micro_f1    : 0.9960    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7979     - val_macro_f1: 0.7533     - val_micro_f1: 0.8640    \n","- Step \u001b[96m  555/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0137     - macro_f1    : 0.9918     - micro_f1    : 0.9957    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8086     - val_macro_f1: 0.7807     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  580/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0142     - macro_f1    : 0.9921     - micro_f1    : 0.9957    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8168     - val_macro_f1: 0.7819     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  605/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0137     - macro_f1    : 0.9922     - micro_f1    : 0.9959    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8256     - val_macro_f1: 0.7479     - val_micro_f1: 0.8660    \n","- Step \u001b[96m  630/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0134     - macro_f1    : 0.9924     - micro_f1    : 0.9960    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8431     - val_macro_f1: 0.7513     - val_micro_f1: 0.8680    \n","- Step \u001b[96m  655/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0142     - macro_f1    : 0.9928     - micro_f1    : 0.9960    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8383     - val_macro_f1: 0.7476     - val_micro_f1: 0.8680    \n","- Step \u001b[96m  680/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0138     - macro_f1    : 0.9932     - micro_f1    : 0.9961    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8353     - val_macro_f1: 0.7523     - val_micro_f1: 0.8700    \n","- Step \u001b[96m  682/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0138     - macro_f1    : 0.9932     - micro_f1    : 0.9961    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8311     - val_macro_f1: 0.7563     - val_micro_f1: 0.8720    \n","Epoch \u001b[92m 14/20\u001b[00m:\n","- Step \u001b[96m   20/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0012     - macro_f1    : 1.0000     - micro_f1    : 1.0000    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8403     - val_macro_f1: 0.7607     - val_micro_f1: 0.8720    \n","- Step \u001b[96m   45/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0212     - macro_f1    : 0.9915     - micro_f1    : 0.9944    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8342     - val_macro_f1: 0.7619     - val_micro_f1: 0.8740    \n","- Step \u001b[96m   70/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0145     - macro_f1    : 0.9957     - micro_f1    : 0.9964    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8273     - val_macro_f1: 0.7616     - val_micro_f1: 0.8720    \n","- Step \u001b[96m   95/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0119     - macro_f1    : 0.9967     - micro_f1    : 0.9974    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8073     - val_macro_f1: 0.7631     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  120/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0114     - macro_f1    : 0.9974     - micro_f1    : 0.9979    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8011     - val_macro_f1: 0.7915     - val_micro_f1: 0.8820    \n","- Step \u001b[96m  145/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0102     - macro_f1    : 0.9978     - micro_f1    : 0.9983    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7975     - val_macro_f1: 0.7882     - val_micro_f1: 0.8800    \n","- Step \u001b[96m  170/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0113     - macro_f1    : 0.9967     - micro_f1    : 0.9978    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7903     - val_macro_f1: 0.7921     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  195/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0102     - macro_f1    : 0.9973     - micro_f1    : 0.9981    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8026     - val_macro_f1: 0.7937     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  220/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0092     - macro_f1    : 0.9976     - micro_f1    : 0.9983    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8210     - val_macro_f1: 0.7935     - val_micro_f1: 0.8820    \n","- Step \u001b[96m  245/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0089     - macro_f1    : 0.9980     - micro_f1    : 0.9985    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8227     - val_macro_f1: 0.7843     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  270/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0084     - macro_f1    : 0.9983     - micro_f1    : 0.9986    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8152     - val_macro_f1: 0.7846     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  295/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0081     - macro_f1    : 0.9985     - micro_f1    : 0.9987    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8455     - val_macro_f1: 0.7834     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  320/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0086     - macro_f1    : 0.9981     - micro_f1    : 0.9984    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8115     - val_macro_f1: 0.7820     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  345/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0088     - macro_f1    : 0.9969     - micro_f1    : 0.9982    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8150     - val_macro_f1: 0.7610     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  370/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0083     - macro_f1    : 0.9973     - micro_f1    : 0.9983    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8056     - val_macro_f1: 0.7694     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  395/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0080     - macro_f1    : 0.9974     - micro_f1    : 0.9984    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8135     - val_macro_f1: 0.7772     - val_micro_f1: 0.8840    \n","- Step \u001b[96m  420/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0086     - macro_f1    : 0.9971     - micro_f1    : 0.9982    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7923     - val_macro_f1: 0.7818     - val_micro_f1: 0.8840    \n","- Step \u001b[96m  445/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0089     - macro_f1    : 0.9962     - micro_f1    : 0.9978    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.7941     - val_macro_f1: 0.7759     - val_micro_f1: 0.8820    \n","- Step \u001b[96m  470/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0092     - macro_f1    : 0.9962     - micro_f1    : 0.9976    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8024     - val_macro_f1: 0.7682     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  495/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0098     - macro_f1    : 0.9960     - micro_f1    : 0.9972    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8215     - val_macro_f1: 0.8065     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  520/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0095     - macro_f1    : 0.9963     - micro_f1    : 0.9974    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8651     - val_macro_f1: 0.8048     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  545/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0092     - macro_f1    : 0.9965     - micro_f1    : 0.9975    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8558     - val_macro_f1: 0.7758     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  570/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0089     - macro_f1    : 0.9966     - micro_f1    : 0.9976    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8624     - val_macro_f1: 0.7598     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  595/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0086     - macro_f1    : 0.9968     - micro_f1    : 0.9977    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8760     - val_macro_f1: 0.7620     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  620/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0090     - macro_f1    : 0.9962     - micro_f1    : 0.9974    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8572     - val_macro_f1: 0.7549     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  645/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0089     - macro_f1    : 0.9964     - micro_f1    : 0.9975    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8709     - val_macro_f1: 0.7518     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  670/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0087     - macro_f1    : 0.9966     - micro_f1    : 0.9976    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8356     - val_macro_f1: 0.7887     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  682/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0086     - macro_f1    : 0.9967     - micro_f1    : 0.9976    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8292     - val_macro_f1: 0.7853     - val_micro_f1: 0.8720    \n","Epoch \u001b[92m 15/20\u001b[00m:\n","- Step \u001b[96m   10/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0456     - macro_f1    : 0.9579     - micro_f1    : 0.9875    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8254     - val_macro_f1: 0.7853     - val_micro_f1: 0.8720    \n","- Step \u001b[96m   35/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0144     - macro_f1    : 0.9731     - micro_f1    : 0.9964    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8201     - val_macro_f1: 0.7853     - val_micro_f1: 0.8720    \n","- Step \u001b[96m   60/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0089     - macro_f1    : 0.9919     - micro_f1    : 0.9979    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8367     - val_macro_f1: 0.7883     - val_micro_f1: 0.8760    \n","- Step \u001b[96m   85/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0066     - macro_f1    : 0.9974     - micro_f1    : 0.9985    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8178     - val_macro_f1: 0.7900     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  110/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0055     - macro_f1    : 0.9982     - micro_f1    : 0.9989    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8185     - val_macro_f1: 0.7900     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  135/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0049     - macro_f1    : 0.9983     - micro_f1    : 0.9991    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8279     - val_macro_f1: 0.7900     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  160/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0043     - macro_f1    : 0.9985     - micro_f1    : 0.9992    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8400     - val_macro_f1: 0.7894     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  185/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0040     - macro_f1    : 0.9989     - micro_f1    : 0.9993    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8543     - val_macro_f1: 0.7858     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  210/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0077     - macro_f1    : 0.9967     - micro_f1    : 0.9982    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8598     - val_macro_f1: 0.7864     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  235/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0072     - macro_f1    : 0.9974     - micro_f1    : 0.9984    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8491     - val_macro_f1: 0.7890     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  260/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0067     - macro_f1    : 0.9976     - micro_f1    : 0.9986    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8398     - val_macro_f1: 0.7862     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  285/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0064     - macro_f1    : 0.9977     - micro_f1    : 0.9987    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8639     - val_macro_f1: 0.7862     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  310/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0076     - macro_f1    : 0.9973     - micro_f1    : 0.9984    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8466     - val_macro_f1: 0.7889     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  335/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0071     - macro_f1    : 0.9975     - micro_f1    : 0.9985    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8451     - val_macro_f1: 0.7871     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  360/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0068     - macro_f1    : 0.9977     - micro_f1    : 0.9986    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8510     - val_macro_f1: 0.7883     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  385/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0064     - macro_f1    : 0.9977     - micro_f1    : 0.9987    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8583     - val_macro_f1: 0.7860     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  410/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0064     - macro_f1    : 0.9978     - micro_f1    : 0.9985    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8613     - val_macro_f1: 0.7876     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  435/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0062     - macro_f1    : 0.9981     - micro_f1    : 0.9986    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8706     - val_macro_f1: 0.7899     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  460/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0080     - macro_f1    : 0.9979     - micro_f1    : 0.9984    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8492     - val_macro_f1: 0.7857     - val_micro_f1: 0.8820    \n","- Step \u001b[96m  485/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0084     - macro_f1    : 0.9977     - micro_f1    : 0.9982    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8621     - val_macro_f1: 0.7907     - val_micro_f1: 0.8820    \n","- Step \u001b[96m  510/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0081     - macro_f1    : 0.9978     - micro_f1    : 0.9983    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8738     - val_macro_f1: 0.7868     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  535/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0078     - macro_f1    : 0.9979     - micro_f1    : 0.9984    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8478     - val_macro_f1: 0.7868     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  560/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0075     - macro_f1    : 0.9980     - micro_f1    : 0.9984    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8755     - val_macro_f1: 0.7906     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  585/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0073     - macro_f1    : 0.9981     - micro_f1    : 0.9985    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8582     - val_macro_f1: 0.7892     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  610/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0070     - macro_f1    : 0.9982     - micro_f1    : 0.9986    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8522     - val_macro_f1: 0.7886     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  635/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0068     - macro_f1    : 0.9982     - micro_f1    : 0.9986    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8695     - val_macro_f1: 0.7886     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  660/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0066     - macro_f1    : 0.9983     - micro_f1    : 0.9987    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8573     - val_macro_f1: 0.7904     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  682/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0065     - macro_f1    : 0.9983     - micro_f1    : 0.9987    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8598     - val_macro_f1: 0.7950     - val_micro_f1: 0.8820    \n","Epoch \u001b[92m 16/20\u001b[00m:\n","- Step \u001b[96m   25/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0017     - macro_f1    : 1.0000     - micro_f1    : 1.0000    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8825     - val_macro_f1: 0.7950     - val_micro_f1: 0.8820    \n","- Step \u001b[96m   50/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0072     - macro_f1    : 0.9912     - micro_f1    : 0.9975    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8577     - val_macro_f1: 0.7714     - val_micro_f1: 0.8800    \n","- Step \u001b[96m   75/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0113     - macro_f1    : 0.9939     - micro_f1    : 0.9967    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8455     - val_macro_f1: 0.7937     - val_micro_f1: 0.8800    \n","- Step \u001b[96m  100/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0092     - macro_f1    : 0.9943     - micro_f1    : 0.9975    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8490     - val_macro_f1: 0.7843     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  125/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0077     - macro_f1    : 0.9961     - micro_f1    : 0.9980    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8445     - val_macro_f1: 0.7843     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  150/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0087     - macro_f1    : 0.9962     - micro_f1    : 0.9975    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8364     - val_macro_f1: 0.7873     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  175/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0076     - macro_f1    : 0.9975     - micro_f1    : 0.9979    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8416     - val_macro_f1: 0.7667     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  200/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0068     - macro_f1    : 0.9976     - micro_f1    : 0.9981    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8618     - val_macro_f1: 0.7716     - val_micro_f1: 0.8800    \n","- Step \u001b[96m  225/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0062     - macro_f1    : 0.9980     - micro_f1    : 0.9983    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8571     - val_macro_f1: 0.7716     - val_micro_f1: 0.8800    \n","- Step \u001b[96m  250/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0059     - macro_f1    : 0.9983     - micro_f1    : 0.9985    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8670     - val_macro_f1: 0.7680     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  275/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0054     - macro_f1    : 0.9984     - micro_f1    : 0.9986    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8708     - val_macro_f1: 0.7679     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  300/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0051     - macro_f1    : 0.9984     - micro_f1    : 0.9988    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.9029     - val_macro_f1: 0.7642     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  325/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0048     - macro_f1    : 0.9985     - micro_f1    : 0.9988    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8836     - val_macro_f1: 0.7798     - val_micro_f1: 0.8700    \n","- Step \u001b[96m  350/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0046     - macro_f1    : 0.9987     - micro_f1    : 0.9989    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8521     - val_macro_f1: 0.7855     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  375/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0045     - macro_f1    : 0.9988     - micro_f1    : 0.9990    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8650     - val_macro_f1: 0.7894     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  400/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0043     - macro_f1    : 0.9988     - micro_f1    : 0.9991    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8541     - val_macro_f1: 0.7889     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  425/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0041     - macro_f1    : 0.9989     - micro_f1    : 0.9991    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8399     - val_macro_f1: 0.7872     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  450/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0046     - macro_f1    : 0.9988     - micro_f1    : 0.9989    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8415     - val_macro_f1: 0.7872     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  475/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0044     - macro_f1    : 0.9989     - micro_f1    : 0.9989    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8453     - val_macro_f1: 0.7855     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  500/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0043     - macro_f1    : 0.9990     - micro_f1    : 0.9990    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8590     - val_macro_f1: 0.7845     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  525/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0053     - macro_f1    : 0.9988     - micro_f1    : 0.9988    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8560     - val_macro_f1: 0.7845     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  550/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0051     - macro_f1    : 0.9989     - micro_f1    : 0.9989    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8631     - val_macro_f1: 0.7851     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  575/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0061     - macro_f1    : 0.9986     - micro_f1    : 0.9985    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8665     - val_macro_f1: 0.7851     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  600/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0059     - macro_f1    : 0.9987     - micro_f1    : 0.9985    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8831     - val_macro_f1: 0.7849     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  625/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0058     - macro_f1    : 0.9987     - micro_f1    : 0.9986    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8643     - val_macro_f1: 0.7849     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  650/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0056     - macro_f1    : 0.9988     - micro_f1    : 0.9987    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8816     - val_macro_f1: 0.7849     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  675/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0055     - macro_f1    : 0.9988     - micro_f1    : 0.9987    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8626     - val_macro_f1: 0.7862     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  682/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0054     - macro_f1    : 0.9988     - micro_f1    : 0.9987    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8649     - val_macro_f1: 0.7862     - val_micro_f1: 0.8760    \n","Epoch \u001b[92m 17/20\u001b[00m:\n","- Step \u001b[96m   15/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0012     - macro_f1    : 1.0000     - micro_f1    : 1.0000    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8838     - val_macro_f1: 0.7862     - val_micro_f1: 0.8760    \n","- Step \u001b[96m   40/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0018     - macro_f1    : 1.0000     - micro_f1    : 1.0000    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8645     - val_macro_f1: 0.7862     - val_micro_f1: 0.8760    \n","- Step \u001b[96m   65/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0015     - macro_f1    : 1.0000     - micro_f1    : 1.0000    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8813     - val_macro_f1: 0.7862     - val_micro_f1: 0.8760    \n","- Step \u001b[96m   90/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0013     - macro_f1    : 1.0000     - micro_f1    : 1.0000    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8603     - val_macro_f1: 0.7862     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  115/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0012     - macro_f1    : 1.0000     - micro_f1    : 1.0000    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8614     - val_macro_f1: 0.7862     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  140/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0023     - macro_f1    : 0.9994     - micro_f1    : 0.9991    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8764     - val_macro_f1: 0.7880     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  165/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0021     - macro_f1    : 0.9995     - micro_f1    : 0.9992    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8553     - val_macro_f1: 0.7862     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  190/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0019     - macro_f1    : 0.9996     - micro_f1    : 0.9993    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8743     - val_macro_f1: 0.7862     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  215/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0037     - macro_f1    : 0.9992     - micro_f1    : 0.9988    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8547     - val_macro_f1: 0.7862     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  240/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0034     - macro_f1    : 0.9993     - micro_f1    : 0.9990    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8567     - val_macro_f1: 0.7793     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  265/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0032     - macro_f1    : 0.9994     - micro_f1    : 0.9991    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8828     - val_macro_f1: 0.7793     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  290/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0038     - macro_f1    : 0.9989     - micro_f1    : 0.9987    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8630     - val_macro_f1: 0.7815     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  315/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0036     - macro_f1    : 0.9990     - micro_f1    : 0.9988    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8536     - val_macro_f1: 0.7885     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  340/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0042     - macro_f1    : 0.9985     - micro_f1    : 0.9985    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8550     - val_macro_f1: 0.7856     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  365/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0039     - macro_f1    : 0.9986     - micro_f1    : 0.9986    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8394     - val_macro_f1: 0.7668     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  390/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0044     - macro_f1    : 0.9983     - micro_f1    : 0.9984    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8649     - val_macro_f1: 0.7668     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  415/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0042     - macro_f1    : 0.9984     - micro_f1    : 0.9985    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8402     - val_macro_f1: 0.7438     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  440/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0041     - macro_f1    : 0.9986     - micro_f1    : 0.9986    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8513     - val_macro_f1: 0.7621     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  465/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0050     - macro_f1    : 0.9984     - micro_f1    : 0.9984    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8383     - val_macro_f1: 0.7602     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  490/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0049     - macro_f1    : 0.9985     - micro_f1    : 0.9985    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8388     - val_macro_f1: 0.7580     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  515/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0047     - macro_f1    : 0.9986     - micro_f1    : 0.9985    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8429     - val_macro_f1: 0.7641     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  540/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0055     - macro_f1    : 0.9985     - micro_f1    : 0.9984    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8459     - val_macro_f1: 0.7641     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  565/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0053     - macro_f1    : 0.9985     - micro_f1    : 0.9985    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8552     - val_macro_f1: 0.7642     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  590/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0052     - macro_f1    : 0.9986     - micro_f1    : 0.9985    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8512     - val_macro_f1: 0.7677     - val_micro_f1: 0.8800    \n","- Step \u001b[96m  615/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0050     - macro_f1    : 0.9987     - micro_f1    : 0.9986    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8527     - val_macro_f1: 0.7676     - val_micro_f1: 0.8800    \n","- Step \u001b[96m  640/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0056     - macro_f1    : 0.9985     - micro_f1    : 0.9984    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8521     - val_macro_f1: 0.7639     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  665/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0054     - macro_f1    : 0.9986     - micro_f1    : 0.9985    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8458     - val_macro_f1: 0.7604     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  682/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0058     - macro_f1    : 0.9984     - micro_f1    : 0.9983    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8789     - val_macro_f1: 0.7604     - val_micro_f1: 0.8760    \n","Epoch \u001b[92m 18/20\u001b[00m:\n","- Step \u001b[96m    5/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0011     - macro_f1    : 1.0000     - micro_f1    : 1.0000    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8416     - val_macro_f1: 0.7639     - val_micro_f1: 0.8780    \n","- Step \u001b[96m   30/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0008     - macro_f1    : 1.0000     - micro_f1    : 1.0000    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8441     - val_macro_f1: 0.7639     - val_micro_f1: 0.8780    \n","- Step \u001b[96m   55/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0039     - macro_f1    : 0.9949     - micro_f1    : 0.9977    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8475     - val_macro_f1: 0.7569     - val_micro_f1: 0.8760    \n","- Step \u001b[96m   80/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0029     - macro_f1    : 0.9965     - micro_f1    : 0.9984    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8546     - val_macro_f1: 0.7553     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  105/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0024     - macro_f1    : 0.9967     - micro_f1    : 0.9988    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8510     - val_macro_f1: 0.7553     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  130/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0029     - macro_f1    : 0.9955     - micro_f1    : 0.9981    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8630     - val_macro_f1: 0.7556     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  155/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0026     - macro_f1    : 0.9964     - micro_f1    : 0.9984    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8534     - val_macro_f1: 0.7572     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  180/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0040     - macro_f1    : 0.9959     - micro_f1    : 0.9979    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8697     - val_macro_f1: 0.7655     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  205/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0037     - macro_f1    : 0.9966     - micro_f1    : 0.9982    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8648     - val_macro_f1: 0.7641     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  230/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0034     - macro_f1    : 0.9968     - micro_f1    : 0.9984    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8747     - val_macro_f1: 0.7641     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  255/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0044     - macro_f1    : 0.9969     - micro_f1    : 0.9980    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8607     - val_macro_f1: 0.7641     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  280/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0041     - macro_f1    : 0.9971     - micro_f1    : 0.9982    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8420     - val_macro_f1: 0.7877     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  305/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0038     - macro_f1    : 0.9974     - micro_f1    : 0.9984    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8519     - val_macro_f1: 0.7861     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  330/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0036     - macro_f1    : 0.9977     - micro_f1    : 0.9985    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8435     - val_macro_f1: 0.7840     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  355/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0047     - macro_f1    : 0.9976     - micro_f1    : 0.9982    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8415     - val_macro_f1: 0.7640     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  380/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0045     - macro_f1    : 0.9977     - micro_f1    : 0.9984    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8485     - val_macro_f1: 0.7624     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  405/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0048     - macro_f1    : 0.9975     - micro_f1    : 0.9981    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8584     - val_macro_f1: 0.7845     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  430/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0046     - macro_f1    : 0.9976     - micro_f1    : 0.9983    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8585     - val_macro_f1: 0.7572     - val_micro_f1: 0.8720    \n","- Step \u001b[96m  455/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0044     - macro_f1    : 0.9977     - micro_f1    : 0.9984    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8618     - val_macro_f1: 0.7601     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  480/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0045     - macro_f1    : 0.9978     - micro_f1    : 0.9984    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8582     - val_macro_f1: 0.7601     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  505/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0043     - macro_f1    : 0.9979     - micro_f1    : 0.9985    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8637     - val_macro_f1: 0.7601     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  530/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0041     - macro_f1    : 0.9980     - micro_f1    : 0.9986    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8663     - val_macro_f1: 0.7601     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  555/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0040     - macro_f1    : 0.9981     - micro_f1    : 0.9986    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.9084     - val_macro_f1: 0.7601     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  580/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0038     - macro_f1    : 0.9982     - micro_f1    : 0.9987    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8689     - val_macro_f1: 0.7601     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  605/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0037     - macro_f1    : 0.9982     - micro_f1    : 0.9988    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8692     - val_macro_f1: 0.7601     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  630/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0036     - macro_f1    : 0.9983     - micro_f1    : 0.9988    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.9140     - val_macro_f1: 0.7601     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  655/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0035     - macro_f1    : 0.9984     - micro_f1    : 0.9989    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8861     - val_macro_f1: 0.7601     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  680/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0034     - macro_f1    : 0.9984     - micro_f1    : 0.9989    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8665     - val_macro_f1: 0.7601     - val_micro_f1: 0.8740    \n","- Step \u001b[96m  682/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0034     - macro_f1    : 0.9984     - micro_f1    : 0.9989    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8772     - val_macro_f1: 0.7601     - val_micro_f1: 0.8740    \n","Epoch \u001b[92m 19/20\u001b[00m:\n","- Step \u001b[96m   20/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0008     - macro_f1    : 1.0000     - micro_f1    : 1.0000    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8668     - val_macro_f1: 0.7601     - val_micro_f1: 0.8740    \n","- Step \u001b[96m   45/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0008     - macro_f1    : 1.0000     - micro_f1    : 1.0000    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8680     - val_macro_f1: 0.7616     - val_micro_f1: 0.8760    \n","- Step \u001b[96m   70/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0007     - macro_f1    : 1.0000     - micro_f1    : 1.0000    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8906     - val_macro_f1: 0.7616     - val_micro_f1: 0.8760    \n","- Step \u001b[96m   95/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0014     - macro_f1    : 1.0000     - micro_f1    : 1.0000    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8676     - val_macro_f1: 0.7616     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  120/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0034     - macro_f1    : 0.9993     - micro_f1    : 0.9990    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8687     - val_macro_f1: 0.7616     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  145/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0030     - macro_f1    : 0.9994     - micro_f1    : 0.9991    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8697     - val_macro_f1: 0.7616     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  170/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0026     - macro_f1    : 0.9995     - micro_f1    : 0.9993    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8699     - val_macro_f1: 0.7616     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  195/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0041     - macro_f1    : 0.9987     - micro_f1    : 0.9987    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8687     - val_macro_f1: 0.7616     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  220/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0037     - macro_f1    : 0.9987     - micro_f1    : 0.9989    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8675     - val_macro_f1: 0.7868     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  245/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0055     - macro_f1    : 0.9982     - micro_f1    : 0.9985    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8645     - val_macro_f1: 0.7868     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  270/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0051     - macro_f1    : 0.9984     - micro_f1    : 0.9986    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8616     - val_macro_f1: 0.7868     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  295/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0058     - macro_f1    : 0.9982     - micro_f1    : 0.9983    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8653     - val_macro_f1: 0.7868     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  320/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0054     - macro_f1    : 0.9985     - micro_f1    : 0.9984    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8525     - val_macro_f1: 0.7868     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  345/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0050     - macro_f1    : 0.9985     - micro_f1    : 0.9986    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8513     - val_macro_f1: 0.7863     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  370/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0047     - macro_f1    : 0.9987     - micro_f1    : 0.9986    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8507     - val_macro_f1: 0.7863     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  395/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0046     - macro_f1    : 0.9987     - micro_f1    : 0.9987    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8510     - val_macro_f1: 0.7863     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  420/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0044     - macro_f1    : 0.9988     - micro_f1    : 0.9988    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8779     - val_macro_f1: 0.7863     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  445/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0042     - macro_f1    : 0.9988     - micro_f1    : 0.9989    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8531     - val_macro_f1: 0.7863     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  470/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0040     - macro_f1    : 0.9989     - micro_f1    : 0.9989    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8579     - val_macro_f1: 0.7876     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  495/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0038     - macro_f1    : 0.9989     - micro_f1    : 0.9990    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8536     - val_macro_f1: 0.7876     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  520/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0037     - macro_f1    : 0.9989     - micro_f1    : 0.9990    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8536     - val_macro_f1: 0.7876     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  545/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0035     - macro_f1    : 0.9990     - micro_f1    : 0.9991    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8537     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  570/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0034     - macro_f1    : 0.9990     - micro_f1    : 0.9991    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8548     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  595/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0043     - macro_f1    : 0.9988     - micro_f1    : 0.9989    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8793     - val_macro_f1: 0.7876     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  620/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0047     - macro_f1    : 0.9987     - micro_f1    : 0.9988    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8737     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  645/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0045     - macro_f1    : 0.9987     - micro_f1    : 0.9988    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8544     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  670/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0044     - macro_f1    : 0.9987     - micro_f1    : 0.9989    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8546     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  682/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0043     - macro_f1    : 0.9988     - micro_f1    : 0.9989    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8547     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","Epoch \u001b[92m 20/20\u001b[00m:\n","- Step \u001b[96m   10/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0005     - macro_f1    : 1.0000     - micro_f1    : 1.0000    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8548     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m   35/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0044     - macro_f1    : 0.9981     - micro_f1    : 0.9964    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8546     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m   60/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0032     - macro_f1    : 0.9989     - micro_f1    : 0.9979    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8546     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m   85/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0024     - macro_f1    : 0.9993     - micro_f1    : 0.9985    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8804     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  110/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0021     - macro_f1    : 0.9994     - micro_f1    : 0.9989    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8558     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  135/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0018     - macro_f1    : 0.9995     - micro_f1    : 0.9991    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8564     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  160/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0016     - macro_f1    : 0.9996     - micro_f1    : 0.9992    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8604     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  185/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0015     - macro_f1    : 0.9997     - micro_f1    : 0.9993    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8567     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  210/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0017     - macro_f1    : 0.9997     - micro_f1    : 0.9994    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8697     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  235/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0016     - macro_f1    : 0.9997     - micro_f1    : 0.9995    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8557     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  260/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0016     - macro_f1    : 0.9998     - micro_f1    : 0.9995    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8775     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  285/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0015     - macro_f1    : 0.9998     - micro_f1    : 0.9996    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8778     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  310/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0015     - macro_f1    : 0.9998     - micro_f1    : 0.9996    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8684     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  335/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0014     - macro_f1    : 0.9998     - micro_f1    : 0.9996    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8558     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  360/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0017     - macro_f1    : 0.9995     - micro_f1    : 0.9993    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8575     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  385/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0017     - macro_f1    : 0.9995     - micro_f1    : 0.9994    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8645     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  410/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0016     - macro_f1    : 0.9995     - micro_f1    : 0.9994    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8572     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  435/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0019     - macro_f1    : 0.9992     - micro_f1    : 0.9991    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8571     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  460/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0018     - macro_f1    : 0.9992     - micro_f1    : 0.9992    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8569     - val_macro_f1: 0.7875     - val_micro_f1: 0.8780    \n","- Step \u001b[96m  485/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0018     - macro_f1    : 0.9993     - micro_f1    : 0.9992    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8826     - val_macro_f1: 0.7687     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  510/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0017     - macro_f1    : 0.9993     - micro_f1    : 0.9993    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8708     - val_macro_f1: 0.7687     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  535/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0017     - macro_f1    : 0.9994     - micro_f1    : 0.9993    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8571     - val_macro_f1: 0.7687     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  560/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0016     - macro_f1    : 0.9994     - micro_f1    : 0.9993    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8896     - val_macro_f1: 0.7687     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  585/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0016     - macro_f1    : 0.9994     - micro_f1    : 0.9994    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8569     - val_macro_f1: 0.7687     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  610/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0022     - macro_f1    : 0.9992     - micro_f1    : 0.9992    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8755     - val_macro_f1: 0.7687     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  635/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0021     - macro_f1    : 0.9993     - micro_f1    : 0.9992    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8568     - val_macro_f1: 0.7687     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  660/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0026     - macro_f1    : 0.9991     - micro_f1    : 0.9991    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8607     - val_macro_f1: 0.7687     - val_micro_f1: 0.8760    \n","- Step \u001b[96m  682/682\u001b[00m:\n","    \u001b[95mTrain result        \u001b[00m - loss    : 0.0026     - macro_f1    : 0.9991     - micro_f1    : 0.9991    \n","    \u001b[95mValidation result   \u001b[00m - val_loss: 0.8786     - val_macro_f1: 0.7687     - val_micro_f1: 0.8760    \n"]}],"source":["!python3 train_qc.py --use-gpu=True --patience-steps=0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NW9is9s5zJo7"},"outputs":[],"source":["import torch\n","from sklearn.metrics import f1_score, accuracy_score\n","from torch.nn import functional as torch_fn\n","from transformers import DataCollatorWithPadding\n","\n","from qa_nlp.dataset import create_QC_dataset, load\n","from qa_nlp.models import QCModel, get_tokenizer\n","from argument_parser import ArgumentParser\n","\n","from qa_nlp.utils import json2dict, load_class, get_gradient_accumulate_steps\n","from scheduler import WarmupLinearLR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LRKWVVqkzfrY"},"outputs":[],"source":["arg_parser = ArgumentParser()\n","\n","arg_parser.define(\"EPOCHS\", default=20, arg_type=int)\n","arg_parser.define(\"lr\", default=2e-5, arg_type=float)\n","arg_parser.define(\"weight-decay\", default=0.001, arg_type=float)\n","arg_parser.define(\"use-gpu\", default=False, arg_type=bool)\n","arg_parser.define(\"warmup-rate\", default=0.1, arg_type=float)\n","arg_parser.define(\"gradient-accumulation-steps\", default=5, arg_type=int)\n","arg_parser.define(\"max-grad-norm\", default=1.0, arg_type=float)\n","arg_parser.define(\"save-steps\", default=5, arg_type=int)\n","arg_parser.define(\"model-name\", default=\"qc/V2023-10-22\", arg_type=str)\n","\n","flags = arg_parser.parse()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"88bapX0Tzidv"},"outputs":[],"source":["def evaluate(model, val_dataloader, val_steps, device):\n","\tmodel.eval()\n","\twith torch.no_grad():\n","\t\ttotal_loss = 0.0\n","\t\ty_trues = []\n","\t\ty_preds = []\n","\n","\t\tfor batch in val_dataloader:\n","\t\t\tinputs = {'input_ids': batch[\"input_ids\"].to(device),\n","\t\t\t          'attention_mask': batch[\"attention_mask\"].to(device),\n","\t\t\t          'token_type_ids': batch[\"token_type_ids\"].to(device)}\n","\n","\t\t\tlogits = model(inputs)\n","\t\t\tpredicts = torch.argmax(logits, dim=-1).cpu().numpy().tolist()\n","\t\t\ty_preds.extend(predicts)\n","\t\t\ty_trues.extend(batch[\"labels\"].numpy().tolist())\n","\n","\t\t\tloss = torch_fn.cross_entropy(logits, batch[\"labels\"].to(device))\n","\t\t\ttotal_loss += loss.item()\n","\n","\t\tf1_score_micro = f1_score(y_trues, y_preds, average=\"micro\")\n","\t\taccuracy = accuracy_score(y_trues, y_preds)\n","\n","\t\tvalidation_result = {\n","\t\t\t\"loss\": round(total_loss / val_steps, 4),\n","\t\t\t\"accuracy\": round(accuracy, 4),\n","\t\t\t\"f1\": round(f1_score_micro, 4)\n","\t\t}\n","\n","\treturn validation_result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LI3atjSozmqL"},"outputs":[],"source":["if __name__ == \"__main__\":\n","\tdevice = torch.device(\"cuda\" if flags.use_gpu and torch.cuda.is_available() else \"cpu\")\n","\n","\tclass_retriever = load_class()\n","\tclass2index = class_retriever[\"class2index\"]\n","\tindex2class = class_retriever[\"index2class\"]\n","\n","\ttokenizer = get_tokenizer(\"bert-base-multilingual-cased\")\n","\ttrain_dataset = create_QC_dataset(\"data/question_classification/vie/train.txt\",\n","\t                                  tokenizer,\n","\t                                  max_length=512,\n","\t                                  class2index=class2index)\n","\tval_dataset = create_QC_dataset(\"data/question_classification/vie/test.txt\",\n","\t                                tokenizer,\n","\t                                max_length=512,\n","\t                                class2index=class2index)\n","\tcollator = DataCollatorWithPadding(tokenizer)\n","\ttrain_dataloader = load(train_dataset, collator, batch_size=8)\n","\tval_dataloader = load(val_dataset, collator, batch_size=8)\n","\n","\tconfig = json2dict(\"assets/model_params/qc-model.json\")\n","\tmodel = QCModel(**config).to(device)\n","\n","\t# Prepare optimizer and schedule (linear warmup and decay)\n","\tno_decay = ['bias', 'LayerNorm.weight']\n","\toptimizer_grouped_parameters = [\n","\t\t{'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","\t\t 'weight_decay': flags.weight_decay},\n","\t\t{'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n","\t\t 'weight_decay': 0.0}\n","\t]\n","\n","\ttotal_steps = (len(train_dataloader) * flags.EPOCHS // flags.gradient_accumulation_steps) + 1\n","\twarmup_steps = int(0.1*total_steps)\n","\tmonitor_f1 = float('-inf')\n","\n","\toptimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=flags.lr, weight_decay=0.0)\n","\tscheduler = WarmupLinearLR(optimizer, warmup_steps, total_steps, min_proportion=0.01)\n","\tsteps_per_epoch = len(train_dataloader)\n","\tglobal_steps = 0\n","\tlog_writer = open(\"logs/train-qc.log\", \"w\")\n","\tlog_writer.write(\"               ***** Start training *****\\n\")\n","\tlog_writer.write(\"============================================================\\n\")\n","\tlog_writer.write(f\"Num samples: {len(train_dataset)}\\n\")\n","\tlog_writer.write(f\"Num epochs: {flags.EPOCHS}\\n\")\n","\tlog_writer.write(f\"Gradient Accumulation steps = {flags.gradient_accumulation_steps}\\n\")\n","\tlog_writer.write(\"============================================================\\n\")\n","\n","\tfor epoch in range(flags.EPOCHS):\n","\t\ttotal_loss = 0.0\n","\t\ty_trues = []\n","\t\ty_preds = []\n","\n","\t\tlog_writer.write(\"------------------------------------------------------------\\n\")\n","\t\tlog_writer.write(f\"Epoch {epoch + 1:>3d}/{flags.EPOCHS}:\\n\")\n","\n","\t\tprint(f\"Epoch \\033[92m{epoch + 1:>3d}/{flags.EPOCHS}\\033[00m:\")\n","\n","\t\tfor step, batch in enumerate(train_dataloader):\n","\t\t\tprint(f\"\\r- Step \\033[96m{step + 1:>5d}/{steps_per_epoch}\\033[00m:\", end=\"\")\n","\n","\t\t\tcurr_acc_step = get_gradient_accumulate_steps(steps_per_epoch, step, flags.gradient_accumulation_steps)\n","\t\t\tmodel.train()\n","\n","\t\t\tinputs = {'input_ids': batch[\"input_ids\"].to(device),\n","\t\t\t          'attention_mask': batch[\"attention_mask\"].to(device),\n","\t\t\t          'token_type_ids': batch[\"token_type_ids\"].to(device)}\n","\n","\t\t\tlogits = model(inputs)\n","\t\t\tpredicts = torch.argmax(logits, dim=-1).cpu().numpy().tolist()\n","\t\t\ty_preds.extend(predicts)\n","\t\t\ty_trues.extend(batch[\"labels\"].numpy().tolist())\n","\n","\t\t\tloss = torch_fn.cross_entropy(logits, batch[\"labels\"].to(device))\n","\t\t\ttotal_loss += loss.item()\n","\t\t\tloss /= curr_acc_step\n","\t\t\tloss.backward()\n","\n","\t\t\tif (step + 1) % flags.gradient_accumulation_steps == 0 or (step == steps_per_epoch - 1):\n","\t\t\t\ttorch.nn.utils.clip_grad_norm_(model.parameters(), flags.max_grad_norm)\n","\n","\t\t\t\toptimizer.step()\n","\t\t\t\tscheduler.step()  # Update learning rate schedule\n","\t\t\t\toptimizer.zero_grad()\n","\t\t\t\tglobal_steps += 1\n","\n","\t\t\t\tif flags.save_steps > 0 and global_steps % flags.save_steps == 0:\n","\t\t\t\t\tprint()\n","\t\t\t\t\tlogging_line = f\"- Step: {step + 1:>5d}/{steps_per_epoch}, lr: {scheduler.get_last_lr()}\\n\"\n","\t\t\t\t\tlog_writer.write(logging_line)\n","\n","\t\t\t\t\tf1_score_micro = f1_score(y_trues, y_preds, average=\"micro\")\n","\t\t\t\t\taccuracy = accuracy_score(y_trues, y_preds)\n","\n","\t\t\t\t\ttrain_accumulate_loss = round(total_loss / (step + 1), 4)\n","\t\t\t\t\ttrain_accumulate_accuracy = round(accuracy, 4)\n","\t\t\t\t\ttrain_accumulate_f1 = round(f1_score_micro, 4)\n","\n","\t\t\t\t\ttrain_result_line = (f\"{'loss':8s}: {train_accumulate_loss:<10.4f} - \"\n","\t\t\t\t\t                     f\"{'accuracy':12s}: {train_accumulate_accuracy:<10.4f} - \"\n","\t\t\t\t\t                     f\"{'f1':6s}: {train_accumulate_f1:<10.4f}\")\n","\n","\t\t\t\t\tprint(f\"    \\033[95m{'Train result':20s}\\033[00m - {train_result_line}\")\n","\t\t\t\t\tlog_writer.write(f\"    {'Train result':20s} - {train_result_line}\\n\")\n","\n","\t\t\t\t\tvalidation_output = evaluate(model, val_dataloader, len(val_dataloader), device)\n","\n","\t\t\t\t\tval_result_line = (f\"val_loss: {validation_output['loss']:<10.4f} - \"\n","\t\t\t\t\t                    f\"val_accuracy: {validation_output['accuracy']:<10.4f} - \"\n","\t\t\t\t\t                    f\"val_f1: {validation_output['f1']:<10.4f}\")\n","\n","\t\t\t\t\tprint(f\"    \\033[95m{'Validation result':20s}\\033[00m - {val_result_line}\")\n","\t\t\t\t\tlog_writer.write(f\"    {'Validation result':20s} - {val_result_line}\\n\")\n","\t\t\t\t\tif validation_output['f1'] > monitor_f1:\n","\t\t\t\t\t\tmodel.save(flags.model_name)\n","\t\t\t\t\t\tlog_writer.write(f\"    # val_f1 improve from {monitor_f1} to {validation_output['f1']}. \"\n","\t\t\t\t\t\t                 f\"Saving model with name \\\"{flags.model_name}\\\"\")\n","\t\t\t\t\t\tmonitor_f1 = validation_output[\"f1\"]\n","\t\t\t\t\tlog_writer.write(\"\\n\")\n","\n","\tlog_writer.write(\"                ***** End training *****\\n\")\n","\tlog_writer.close()\n"]},{"cell_type":"markdown","metadata":{"id":"IoE0g-BSSwjV"},"source":["# Run QA"]},{"cell_type":"markdown","metadata":{"id":"kO0-4oy3Zg-f"},"source":["Type: **[CLS]** (Type) (Question) **[SEP]** (Text) **[SEP]**"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":418,"status":"ok","timestamp":1698480044792,"user":{"displayName":"SFVN Gamer","userId":"14323276225791406360"},"user_tz":-420},"id":"LTp_jvIYSby4","outputId":"63c6d846-3ea3-4ee0-f358-eeb53336ecfc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Question Answering\n","...\n","Best result: \u001b[92m0.8212\u001b[00m:\n"]}],"source":["!python3 train_qa.py --save-checkpoint=false --EPOCHS=6"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NtUb908hTOAF"},"outputs":[],"source":["# check answer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AOHw8yGKf7s2"},"outputs":[],"source":["loaded_model = torch.load(\"save/model-QA2.pt\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyP9suFwleNoZJXGJZ9g46rG","gpuType":"T4","mount_file_id":"1GQ7J4nxoXb-c46m74v0sQZM4X33zTYFk","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
