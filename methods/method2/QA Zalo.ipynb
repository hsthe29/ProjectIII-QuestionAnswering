{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOl6HW+rz0zwDYG1G5zVLsq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"5337e02d8c0241578f8888453476a552":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0aaa5cdefcf34b4b812ef686d9865716","IPY_MODEL_a0177f524bf0487e8054b1201446ae82","IPY_MODEL_f393cc8562cb4749a84a823a436cb20f"],"layout":"IPY_MODEL_eec34259ce1c4910920aab54b055c65d"}},"0aaa5cdefcf34b4b812ef686d9865716":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0651e32b4c647209edcb679407541c5","placeholder":"​","style":"IPY_MODEL_4e24d96631b44d24b34bc33f177f88fa","value":"Downloading (…)lve/main/config.json: 100%"}},"a0177f524bf0487e8054b1201446ae82":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c63b733c2374a0b95b4509f964eac6c","max":615,"min":0,"orientation":"horizontal","style":"IPY_MODEL_948c1923a51443689d18b843c16f1611","value":615}},"f393cc8562cb4749a84a823a436cb20f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc1aee373f7f49929993fe7584565f5e","placeholder":"​","style":"IPY_MODEL_bfb60d4c5aeb4902b4d469e498f847cf","value":" 615/615 [00:00&lt;00:00, 15.2kB/s]"}},"eec34259ce1c4910920aab54b055c65d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0651e32b4c647209edcb679407541c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e24d96631b44d24b34bc33f177f88fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c63b733c2374a0b95b4509f964eac6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"948c1923a51443689d18b843c16f1611":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cc1aee373f7f49929993fe7584565f5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfb60d4c5aeb4902b4d469e498f847cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"815427d348834b0d9fda5ac156811a6f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_11f45cafafb04a728a5107520e1b1b9b","IPY_MODEL_f82c065814ef487491e1b6b4b1f9f745","IPY_MODEL_e3aaea0b6c654d8798333bdfbde91640"],"layout":"IPY_MODEL_ea036c829ed74006bcb2fc7b48154c79"}},"11f45cafafb04a728a5107520e1b1b9b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74e7dbbc6ae540a6a088bd99bac4d31a","placeholder":"​","style":"IPY_MODEL_314ad81d9e564c9a9de5a8c3c10d9359","value":"Downloading (…)tencepiece.bpe.model: 100%"}},"f82c065814ef487491e1b6b4b1f9f745":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_13dcb41ca2cf4a02adb7d8d6729b833d","max":5069051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2e34547fcab647c29180697ac90f2d27","value":5069051}},"e3aaea0b6c654d8798333bdfbde91640":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75bdba1f0fec4a4fb6a5ddf8f209e505","placeholder":"​","style":"IPY_MODEL_11858138224f48fc8a23b9e12635332d","value":" 5.07M/5.07M [00:00&lt;00:00, 13.9MB/s]"}},"ea036c829ed74006bcb2fc7b48154c79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74e7dbbc6ae540a6a088bd99bac4d31a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"314ad81d9e564c9a9de5a8c3c10d9359":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13dcb41ca2cf4a02adb7d8d6729b833d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e34547fcab647c29180697ac90f2d27":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"75bdba1f0fec4a4fb6a5ddf8f209e505":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11858138224f48fc8a23b9e12635332d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7576956b8914751bfe130cdc2a89fc5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_959bfcf1563d405f88a4f806cd4ae543","IPY_MODEL_c15b634878034ad695aa7c335fdbf8da","IPY_MODEL_880b47c661304a669e996448b7c823ef"],"layout":"IPY_MODEL_b206fbf7cdf44811bfd6b72a4b47d3b1"}},"959bfcf1563d405f88a4f806cd4ae543":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f45b6e8f9be446ff801f9f8e7946ad1f","placeholder":"​","style":"IPY_MODEL_44ffbfe96c9548929fb4ace75e5c8510","value":"Downloading (…)/main/tokenizer.json: 100%"}},"c15b634878034ad695aa7c335fdbf8da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7603ecc24a0c47afb4a06d5e5842b660","max":9096718,"min":0,"orientation":"horizontal","style":"IPY_MODEL_38391e334ae444b299c0751a4f78d48b","value":9096718}},"880b47c661304a669e996448b7c823ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d4be03f7cfa464b9cea25ad1045c24e","placeholder":"​","style":"IPY_MODEL_47b0ab6b951c4b79aeed24ac5e77c516","value":" 9.10M/9.10M [00:00&lt;00:00, 33.8MB/s]"}},"b206fbf7cdf44811bfd6b72a4b47d3b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f45b6e8f9be446ff801f9f8e7946ad1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44ffbfe96c9548929fb4ace75e5c8510":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7603ecc24a0c47afb4a06d5e5842b660":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38391e334ae444b299c0751a4f78d48b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7d4be03f7cfa464b9cea25ad1045c24e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47b0ab6b951c4b79aeed24ac5e77c516":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f346ff6bda9f479c8b6dca3d37850f4c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2af6b54424ea4444b177babe9d671eaf","IPY_MODEL_949d8691cfa9416db5dc3c39ead0d4bd","IPY_MODEL_757003d77b7341c79d7e59d62bbe238f"],"layout":"IPY_MODEL_6dcea3f28e164d82a7864b4e67dee031"}},"2af6b54424ea4444b177babe9d671eaf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67b93c3b3e184bffa4d277410d1c0ab5","placeholder":"​","style":"IPY_MODEL_b0852dfff4a2447888d97dd56b17d697","value":"Downloading model.safetensors: 100%"}},"949d8691cfa9416db5dc3c39ead0d4bd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ce920eb7e6146819fc0116ecda41a50","max":1115567652,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b2b338527e8d44fba42c3d5c6025c5e1","value":1115567652}},"757003d77b7341c79d7e59d62bbe238f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_024f75eecad049a5a9e536495762f6c1","placeholder":"​","style":"IPY_MODEL_18146f06cff241a9a8b4509c7663dd98","value":" 1.12G/1.12G [00:09&lt;00:00, 74.0MB/s]"}},"6dcea3f28e164d82a7864b4e67dee031":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67b93c3b3e184bffa4d277410d1c0ab5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0852dfff4a2447888d97dd56b17d697":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ce920eb7e6146819fc0116ecda41a50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2b338527e8d44fba42c3d5c6025c5e1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"024f75eecad049a5a9e536495762f6c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18146f06cff241a9a8b4509c7663dd98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fnIfAD1Dg9HY","executionInfo":{"status":"ok","timestamp":1699661780791,"user_tz":-420,"elapsed":26602,"user":{"displayName":"SFVN Gamer","userId":"14323276225791406360"}},"outputId":"bd94873f-f1c3-49f7-9d3e-e800748239e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers[sentencepiece]\n","  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.13.1)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers[sentencepiece])\n","  Downloading huggingface_hub-0.19.0-py3-none-any.whl (311 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2.31.0)\n","Collecting tokenizers<0.15,>=0.14 (from transformers[sentencepiece])\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers[sentencepiece])\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (4.66.1)\n","Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece])\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.20.3)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[sentencepiece]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[sentencepiece]) (4.5.0)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers[sentencepiece])\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2023.7.22)\n","Installing collected packages: sentencepiece, safetensors, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 sentencepiece-0.1.99 tokenizers-0.14.1 transformers-4.35.0\n"]}],"source":["!pip install transformers[sentencepiece]"]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","import torch.nn.functional as tf\n","\n","from torch.utils.data import Dataset, DataLoader\n","\n","from transformers import AutoTokenizer, AutoModel, BatchEncoding, DataCollatorWithPadding\n","\n","from tqdm import tqdm\n","\n","import math\n","import os"],"metadata":{"id":"NqsTZp6zhJdH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pretrained_base_model_name = \"xlm-roberta-base\""],"metadata":{"id":"cBh4C8qlDWdg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cls_pool(features, attention_mask):\n","  '''\n","    features: (N, T, D) -> (N, D)| [(N, T, D)] -> [(N, D)]\n","  '''\n","  if isinstance(features, tuple):\n","    pool_result = ()\n","    for _, f in enumerate(features):\n","      pool_result += (f[:, 0, :],)\n","    return torch.cat(pool_result, dim=-1)\n","  else:\n","    return features[:, 0, :]\n","\n","def masked_mean_pool(features, attention_mask):\n","  '''\n","    features: (N, T, D) -> (N, D) | [(N, T, D)] -> [(N, D)]\n","    attention_mask: (N, T) -> (N, T, 1) for broadcasting element wise multiplication\n","  '''\n","  extended_attention_mask = attention_mask[:, :, None].to(dtype=torch.float32)\n","  if isinstance(features, tuple):\n","    pool_result = ()\n","    for _, f in enumerate(features):\n","      masked_features = torch.mul(f, extended_attention_mask)\n","      pool_result += (torch.sum(masked_features, dim=1)/torch.sum(extended_attention_mask, dim=1),)\n","\n","    return torch.cat(pool_result, dim=-1)\n","  else:\n","    masked_features = torch.mul(features, extended_attention_mask)\n","    return torch.sum(masked_features, dim=1)/torch.sum(extended_attention_mask, dim=1)"],"metadata":{"id":"P4jdMHDijJZw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ACT_MAPPER = {\n","    \"gelu\": tf.gelu,\n","    \"tanh\": tf.tanh,\n","    \"hardtanh\": tf.hardtanh,\n","    \"linear\": tf.linear,\n","    None: tf.linear\n","}\n","POOL_MAPPER = {\n","    \"cls\": cls_pool,\n","    \"mean\": masked_mean_pool\n","}"],"metadata":{"id":"MMZCVOYailmq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Classifier(nn.Module):\n","  def __init__(self, num_classes, input_size, intermediate_size, act_fn):\n","    super(Classifier, self).__init__()\n","\n","    self.fc = nn.Linear(input_size, intermediate_size)\n","    self.output_fc = nn.Linear(intermediate_size, num_classes)\n","    self.act_fn = act_fn\n","\n","    self.__init_weights()\n","\n","  def __init_weights(self):\n","    nn.init.kaiming_normal_(self.fc.weight)\n","    nn.init.xavier_normal_(self.output_fc.weight)\n","\n","  def forward(self, x):\n","    x = self.act_fn(self.fc(x))\n","    logits = self.output_fc(x)\n","    return logits"],"metadata":{"id":"iLvQ6l0DrRXY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BoolQuestionAnswering(nn.Module):\n","  def __init__(self, base_model_name, num_classes, classifier_activation=\"gelu\", pool_method=\"cls\", output_hidden_layers=1, intermediate_size_proportion=4):\n","    super(BoolQuestionAnswering, self).__init__()\n","\n","    self.num_classes = num_classes\n","\n","    if pool_method is None or output_hidden_layers < 1:\n","      raise ValueError()\n","\n","    self.pool_method = POOL_MAPPER[pool_method]\n","    self.output_hidden_layers = output_hidden_layers\n","\n","    self.feature_extractor = AutoModel.from_pretrained(base_model_name, output_hidden_states=output_hidden_layers > 1)\n","\n","    self.hidden_size = 768\n","    self.cls_input_size = output_hidden_layers*self.hidden_size\n","    self.intermediate_size = self.hidden_size*intermediate_size_proportion\n","\n","    self.classifier = Classifier(num_classes, self.cls_input_size, self.intermediate_size, ACT_MAPPER[classifier_activation])\n","\n","    self.loss_fn = tf.cross_entropy\n","\n","  def forward(self, input_ids, attention_mask):\n","    outputs = self.feature_extractor(input_ids, attention_mask)\n","    if self.output_hidden_layers > 1:\n","      features = outputs.hidden_states[-self.output_hidden_layers:]\n","    else:\n","      features = outputs.last_hidden_state\n","\n","    pooled_features = self.pool_method(features, attention_mask)\n","\n","    logits = self.classifier(pooled_features)\n","    return logits\n","\n","  def save(self, model_name: str, weights_only: bool = True):\n","    save_path = os.path.join(\"save\", model_name)\n","    # Check whether the specified path exists or not\n","    is_exist = os.path.exists(save_path)\n","    if not is_exist:\n","      # Create a new directory because it does not exist\n","      os.makedirs(save_path)\n","    else:\n","      print(f\"There is already a model saved with the name {model_name}, which will be overwritten by new version!\")\n","    if weights_only:\n","      weights_file = \"qa-weights.pt\"\n","      torch.save(self.state_dict(), os.path.join(save_path, weights_file))\n","    else:\n","      model_file = \"qa-model.pt\"\n","      torch.save(self, os.path.join(save_path, model_file))\n","\n","\n"],"metadata":{"id":"ExkbrAxghpvQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ViQuAD data"],"metadata":{"id":"gZjQPOzovYwp"}},{"cell_type":"code","source":["def load_tokenizer(tokenizer_name):\n","  return AutoTokenizer.from_pretrained(tokenizer_name)"],"metadata":{"id":"BzpjyBohp-rd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = load_tokenizer(pretrained_base_model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["5337e02d8c0241578f8888453476a552","0aaa5cdefcf34b4b812ef686d9865716","a0177f524bf0487e8054b1201446ae82","f393cc8562cb4749a84a823a436cb20f","eec34259ce1c4910920aab54b055c65d","e0651e32b4c647209edcb679407541c5","4e24d96631b44d24b34bc33f177f88fa","2c63b733c2374a0b95b4509f964eac6c","948c1923a51443689d18b843c16f1611","cc1aee373f7f49929993fe7584565f5e","bfb60d4c5aeb4902b4d469e498f847cf","815427d348834b0d9fda5ac156811a6f","11f45cafafb04a728a5107520e1b1b9b","f82c065814ef487491e1b6b4b1f9f745","e3aaea0b6c654d8798333bdfbde91640","ea036c829ed74006bcb2fc7b48154c79","74e7dbbc6ae540a6a088bd99bac4d31a","314ad81d9e564c9a9de5a8c3c10d9359","13dcb41ca2cf4a02adb7d8d6729b833d","2e34547fcab647c29180697ac90f2d27","75bdba1f0fec4a4fb6a5ddf8f209e505","11858138224f48fc8a23b9e12635332d","e7576956b8914751bfe130cdc2a89fc5","959bfcf1563d405f88a4f806cd4ae543","c15b634878034ad695aa7c335fdbf8da","880b47c661304a669e996448b7c823ef","b206fbf7cdf44811bfd6b72a4b47d3b1","f45b6e8f9be446ff801f9f8e7946ad1f","44ffbfe96c9548929fb4ace75e5c8510","7603ecc24a0c47afb4a06d5e5842b660","38391e334ae444b299c0751a4f78d48b","7d4be03f7cfa464b9cea25ad1045c24e","47b0ab6b951c4b79aeed24ac5e77c516"]},"id":"d_FIVgiFqAbs","executionInfo":{"status":"ok","timestamp":1699661796906,"user_tz":-420,"elapsed":1801,"user":{"displayName":"SFVN Gamer","userId":"14323276225791406360"}},"outputId":"5eae78c6-74ab-487e-9889-f91a26a1ec18"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5337e02d8c0241578f8888453476a552"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"815427d348834b0d9fda5ac156811a6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7576956b8914751bfe130cdc2a89fc5"}},"metadata":{}}]},{"cell_type":"code","source":["def read_data(input_file):\n","    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n","        columns = f.readline().strip().split('\\t')\n","        data = {col_name: [] for col_name in columns}\n","        num_cols = len(columns)\n","        n = 0\n","        for line in f:\n","            n += 1\n","            line = line.replace('\\n', \"\")\n","            values = line.split(\"\\t\")\n","            if len(values) != num_cols:\n","                raise ValueError(f\"Expected {num_cols} columns, found {len(values)} columns!\")\n","            for i in range(len(values)):\n","                data[columns[i]].append(values[i])\n","\n","    # ['title', 'context', 'question', 'label', 'category']\n","\n","    del data[\"title\"]\n","    data[\"size\"] = n\n","    return data"],"metadata":{"id":"29J0HKuBvvj2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def convert_data_to_samples(data, tokenizer, max_chunk_size=512, chunk_overlap_size=256):\n","  def find_context_start_index(sequence_ids):\n","    for i in range(len(sequence_ids)):\n","      if sequence_ids[i] == 2:\n","        return i + 2\n","    return 0\n","\n","  def find_context_end_index(sequence_ids):\n","    for i in range(len(sequence_ids)-1, 0, -1):\n","      if sequence_ids[i] == 2:\n","        return i - 1\n","    return len(sequence_ids)\n","\n","  questions = data[\"question\"]\n","  contexts = data[\"context\"]\n","  labels = data[\"label\"]\n","  categories = data[\"category\"]\n","\n","  all_samples = []\n","\n","  for i in tqdm(range(data[\"size\"])):\n","    question = questions[i]\n","    context = contexts[i]\n","    has_answer = has_answer_list[i]\n","    start_index = int(start_index_list[i])\n","    answer = answers[i]\n","\n","    answer_len = len(answer)\n","\n","    end_index = start_index + answer_len\n","\n","    encoding = tokenizer(question,\n","                         context,\n","                         truncation=\"only_second\",\n","                         max_length=max_chunk_size\n","                         padding=\"max_length\")\n","\n","    all_samples.append(encoding)\n","\n","  return all_samples\n"],"metadata":{"id":"FC1dDi0mweGM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class QADataset(Dataset):\n","  def __init__(self, encodings):\n","        self.encodings = encodings\n","        self.num_samples = len(encodings)\n","\n","  def __len__(self):\n","      return self.num_samples\n","\n","  def __getitem__(self, idx):\n","      encoding = self.encodings[idx]\n","\n","      return encoding\n","\n","def create_dataset(input_file, tokenizer):\n","  data = read_data(input_file)\n","  train_samples = convert_data_to_samples(data, tokenizer)\n","  ds = QADataset(train_samples)\n","  return ds"],"metadata":{"id":"kuoPIckl4yyC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!gdown --id 1JwUYWOaYU71vesQHLsmRxxeSQKMLV14F\n","!gdown --id 1MX2nS5uTns7aUfAn71kJWt-2pmBcKVQh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HRj8uNoT274h","executionInfo":{"status":"ok","timestamp":1699661802720,"user_tz":-420,"elapsed":5417,"user":{"displayName":"SFVN Gamer","userId":"14323276225791406360"}},"outputId":"476ee862-24ba-4b7c-fc3f-e1d91d4681cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1JwUYWOaYU71vesQHLsmRxxeSQKMLV14F\n","To: /content/train.tsv\n","100% 35.8M/35.8M [00:00<00:00, 96.1MB/s]\n","/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1MX2nS5uTns7aUfAn71kJWt-2pmBcKVQh\n","To: /content/dev.tsv\n","100% 10.8M/10.8M [00:00<00:00, 87.6MB/s]\n"]}]},{"cell_type":"code","source":["train_ds = create_dataset(\"/content/train.tsv\", tokenizer)\n","val_ds = create_dataset(\"/content/dev.tsv\", tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xx6x6P7qCysP","executionInfo":{"status":"ok","timestamp":1699661860405,"user_tz":-420,"elapsed":56964,"user":{"displayName":"SFVN Gamer","userId":"14323276225791406360"}},"outputId":"19a00512-b172-449a-c9ee-d1fd277d80cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 28457/28457 [00:44<00:00, 635.79it/s]\n","100%|██████████| 8537/8537 [00:11<00:00, 735.72it/s]\n"]}]},{"cell_type":"code","source":["train_dataloader = DataLoader(train_ds, collate_fn=DataCollatorWithPadding(tokenizer), shuffle=True, batch_size=4)\n","val_dataloader = DataLoader(val_ds, collate_fn=DataCollatorWithPadding(tokenizer), shuffle=True, batch_size=4)"],"metadata":{"id":"WdXipKpODEb5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Optimizer"],"metadata":{"id":"PozI0BCaCgkS"}},{"cell_type":"code","source":["from sklearn.metrics import f1_score, accuracy_score\n","from torch.optim.lr_scheduler import LRScheduler"],"metadata":{"id":"7dYnRBaVCk6R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class WarmupLinearLR(LRScheduler):\n","    def __init__(self,\n","                 optimizer,\n","                 warmup_steps,\n","                 total_steps,\n","                 min_proportion=0.0,\n","                 last_epoch=-1,\n","                 verbose=False):\n","\n","        self.warmup_steps = warmup_steps\n","        self.max_steps = (total_steps - min_proportion * warmup_steps) / (1.0 - min_proportion)\n","        super(WarmupLinearLR, self).__init__(optimizer, last_epoch, verbose)\n","\n","    def get_lr(self):\n","        if self.last_epoch == 0:\n","            return [group['lr'] * 0.1 / self.warmup_steps for group in self.optimizer.param_groups]\n","\n","        if self.last_epoch > self.max_steps:\n","            return [group['lr'] for group in self.optimizer.param_groups]\n","\n","        if self.last_epoch < self.warmup_steps:\n","            return [group['initial_lr'] * self.last_epoch / self.warmup_steps for group in self.optimizer.param_groups]\n","        else:\n","            return [group['initial_lr'] * (self.max_steps - self.last_epoch) / (self.max_steps - self.warmup_steps) for\n","                    group in self.optimizer.param_groups]\n","\n","    def _get_closed_form_lr(self):\n","        if self.last_epoch < self.warmup_steps:\n","            return [base_lr * self.last_epoch / self.warmup_steps for base_lr in self.base_lrs]\n","        else:\n","            return [base_lr * (self.max_steps - self.last_epoch) / (self.max_steps - self.warmup_steps) for base_lr\n","                    in self.base_lrs]\n"],"metadata":{"id":"ngZnK8SFCru2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 10\n","gradient_accumulation_steps = 8\n","batchs_per_epoch = len(train_dataloader)\n","total_steps = EPOCHS * math.ceil(len(train_dataloader) / gradient_accumulation_steps)\n","warmup_steps = int(total_steps*0.1)"],"metadata":{"id":"34FdoIIQCu60"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NVbWG6TFDkuM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"hh8bu6phCifX"}},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"HniPDYbCDrk0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = BoolQuestionAnswering(pretrained_base_model_name, num_classes=2, pool_method=\"mean\").to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["f346ff6bda9f479c8b6dca3d37850f4c","2af6b54424ea4444b177babe9d671eaf","949d8691cfa9416db5dc3c39ead0d4bd","757003d77b7341c79d7e59d62bbe238f","6dcea3f28e164d82a7864b4e67dee031","67b93c3b3e184bffa4d277410d1c0ab5","b0852dfff4a2447888d97dd56b17d697","9ce920eb7e6146819fc0116ecda41a50","b2b338527e8d44fba42c3d5c6025c5e1","024f75eecad049a5a9e536495762f6c1","18146f06cff241a9a8b4509c7663dd98"]},"id":"lGV9N6JPDsUE","executionInfo":{"status":"ok","timestamp":1699661881567,"user_tz":-420,"elapsed":20728,"user":{"displayName":"SFVN Gamer","userId":"14323276225791406360"}},"outputId":"59d768e9-b350-41e7-f44d-4d374ca3ce60"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f346ff6bda9f479c8b6dca3d37850f4c"}},"metadata":{}}]},{"cell_type":"code","source":["weights_files = [\n","    \"bert-base-weights.pt\",\n","    \"xlmr-base-weights.pt\",\n","    \"distilbert-base-weights.pt\"\n","]"],"metadata":{"id":"Vz84aUUv0xfW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load(\"/content/xlm-r-weights.pt\"))"],"metadata":{"id":"bsjL7bFu0l8p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","  {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","    'weight_decay': 0.001},\n","  {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n","    'weight_decay': 0.0}\n","]"],"metadata":{"id":"iL-biPLwEDa7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sum(p.numel() for p in model.parameters())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fDo8JJ6sEGCd","executionInfo":{"status":"ok","timestamp":1699661881567,"user_tz":-420,"elapsed":11,"user":{"displayName":"SFVN Gamer","userId":"14323276225791406360"}},"outputId":"ee4173a0-53e7-418b-d6c7-4d4846025a20"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["280412162"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=2e-5, weight_decay=0.0)\n","scheduler = WarmupLinearLR(optimizer, warmup_steps, total_steps, min_proportion=0.0)"],"metadata":{"id":"Y3KrSaZLEKww"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_grad_norm = 1.0\n","eval_steps = 62\n","save_checkpoint = True"],"metadata":{"id":"wNtNlogiEQpo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir logs\n","!mkdir save"],"metadata":{"id":"ZAbhRAV9EWDh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, val_dataloader, val_steps):\n","    model.eval()\n","    with torch.no_grad():\n","        total_loss = 0.0\n","        y_trues = []\n","        y_preds = []\n","\n","        for batch in val_dataloader:\n","            batch = batch.to(device)\n","\n","            logits = model(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"])\n","\n","            expanded_targets = batch[\"labels\"][:, None]\n","\n","            probabilities_targets = torch.cat((1.0 - expanded_targets, expanded_targets), dim=1)\n","\n","            loss = tf.cross_entropy(logits, probabilities_targets)\n","\n","            labels = (batch[\"labels\"] > 0.5).int()\n","\n","            predicts = torch.argmax(logits, dim=1)\n","            y_preds.extend(predicts.cpu().numpy().tolist())\n","            y_trues.extend(labels.cpu().numpy().tolist())\n","\n","            total_loss += loss.item()\n","\n","        f1 = f1_score(y_trues, y_preds, average=\"weighted\")\n","        accuracy = accuracy_score(y_trues, y_preds)\n","\n","        validation_result = {\n","            \"loss\": round(total_loss / val_steps, 4),\n","            \"accuracy\": round(accuracy, 4),\n","            \"f1\": round(f1, 4)\n","        }\n","\n","    return validation_result\n"],"metadata":{"id":"c3yIhgCcEXe7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["log_writer = open(\"logs/train-qa.log\", \"w\")\n","log_writer.write(\"               ***** Start training *****\\n\")\n","log_writer.write(\"============================================================\\n\")\n","log_writer.write(f\"Num samples: {len(train_ds)}\\n\")\n","log_writer.write(f\"Num epochs: {EPOCHS}\\n\")\n","log_writer.write(f\"Gradient accumulation steps = {gradient_accumulation_steps}\\n\")\n","log_writer.write(\"============================================================\\n\")\n","\n","monitor_f1 = float('-inf')\n","\n","step = 0\n","global_steps = 0\n","\n","optimizer.zero_grad()\n","\n","for epoch in range(EPOCHS):\n","\n","    total_loss = 0.0\n","    y_trues = []\n","    y_preds = []\n","\n","    log_writer.write(\"------------------------------------------------------------\\n\")\n","    log_writer.write(f\"Epoch {epoch + 1:>3d}/{EPOCHS}:\\n\")\n","\n","    print(f\"\\033[92mEpoch\\033[00m {epoch + 1:>3d}/{EPOCHS}:\")\n","\n","    for batch_idx, batch in enumerate(train_dataloader):\n","        # print(f\"\\r- \\033[96mStep\\033[00m {step + 1:>5d}/{steps_per_epoch}:\", end=\"\")\n","\n","        model.train()\n","\n","        batch = batch.to(device)\n","\n","        logits = model(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"])\n","\n","        expanded_targets = batch[\"labels\"][:, None]\n","\n","        probabilities_targets = torch.cat((1.0 - expanded_targets, expanded_targets), dim=1)\n","\n","        loss = model.loss_fn(logits, probabilities_targets)\n","\n","        print(f\"\\r- \\033[96mBatch\\033[00m {batch_idx + 1:>4d}/{batchs_per_epoch} \"\n","              f\"(\\033[96mstep\\033[00m {step + 1}) \"\n","              f\"(\\033[96mglobal step\\033[00m {global_steps + 1}): \"\n","              f\"batch loss: {round(loss.item(), 4)}\", end=\"\")\n","\n","        labels = (batch[\"labels\"] > 0.5).int()\n","\n","        predicts = torch.argmax(logits, dim=1)\n","        y_preds.extend(predicts.cpu().numpy().tolist())\n","        y_trues.extend(labels.cpu().numpy().tolist())\n","\n","        total_loss += loss.item()\n","        loss /= gradient_accumulation_steps\n","        loss.backward()\n","\n","        if (step + 1) % gradient_accumulation_steps == 0:\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","\n","            optimizer.step()  # Update gradients\n","            scheduler.step()  # Update learning rate schedule\n","\n","            global_steps += 1\n","\n","            optimizer.zero_grad()\n","\n","            if global_steps % eval_steps == 0:\n","                print()\n","                logging_line = (f\"\\r- \\033[96mBatch\\033[00m {batch_idx + 1:>4d}/{batchs_per_epoch} \"\n","                                f\"(\\033[96mstep\\033[00m {step + 1}) \"\n","                                f\"(\\033[96mglobal step\\033[00m {global_steps + 1}): \"\n","                                f\"lr: {scheduler.get_last_lr()}\\n\")\n","\n","                log_writer.write(logging_line)\n","\n","                f1 = f1_score(y_trues, y_preds, average=\"weighted\")\n","                accuracy = accuracy_score(y_trues, y_preds)\n","\n","                train_acc_loss = round(total_loss / (batch_idx + 1), 4)\n","                train_acc_f1 = round(f1, 4)\n","                train_acc_accuracy = round(accuracy, 4)\n","\n","                train_result_line = (f\"\\033[95m{'loss':8s}\\033[00m: {train_acc_loss:<10.4f} \"\n","                                     f\"\\033[95m{'accuracy':12s}\\033[00m: {train_acc_accuracy:<10.4f} \"\n","                                     f\"\\033[95m{'f1':6s}\\033[00m: {train_acc_f1:<10.4f}\")\n","\n","                print(f\"    {train_result_line}\")\n","                log_writer.write(f\"    {train_result_line}\\n\")\n","\n","                validation_output = evaluate(model, val_dataloader, len(val_dataloader))\n","\n","                val_result_line = (f\"\\033[95mval_loss\\033[00m: {validation_output['loss']:<10.4f} \"\n","                                   f\"\\033[95mval_accuracy\\033[00m: {validation_output['accuracy']:<10.4f} \"\n","                                   f\"\\033[95mval_f1\\033[00m: {validation_output['f1']:<10.4f}\")\n","\n","                print(f\"    {val_result_line}\")\n","                log_writer.write(f\"    {val_result_line}\\n\")\n","                if save_checkpoint:\n","                    if validation_output['f1'] > monitor_f1:\n","                        model.save(\"xlm-roberta-base-qa\")\n","                        log_writer.write(\n","                          f\"    # val_f1 improve from {monitor_f1} to {validation_output['f1']}. \"\n","                          \"Saving model with name \\\"xlm-roberta-base-qa\\\"\")\n","                        monitor_f1 = validation_output[\"f1\"]\n","\n","                log_writer.write(\"\\n\")\n","\n","        step += 1\n","\n","log_writer.write(\"                ***** End training *****\\n\")\n","log_writer.close()"],"metadata":{"id":"zs5Q-0TuAy0z"},"execution_count":null,"outputs":[]}]}